\chapter{Theory, Background, Existing Literature}
\label{chap:background}

%explain user experience as well - operationalise it - how it will be evaluated. As well as UCD and more on the role of the chatbot

To understand the scope of research related to the interaction between chatbots and humans, and to understand what important factors to consider to design chatbot personalities, the researcher conducted a literature review as part of the course IMT4215 Specialisation Project. This review investigated the scope of research as it related to how humans perceive computers that talk, by looking at research related to the effect anthropomorphism, humanness, and personality have on the user experience of conversational interfaces. The review was concerned with theories in human-computer interaction research, while also exploring human-robot interaction, and theories within human factors and psychology. Through this review the researcher found that emotional intelligence, anthropomorphism, humanness, politeness, human etiquette, humour and gender are important variables to consider when designing a CA, as these are important to how users perceive and experience a CA. In addition, the review also found that researchers \citep{callejas2011,Xiao2005,McTear2016a} (Callejas, 2011, Xiao et al., 2005, McTear et al., 2016a) believe that personality can be used as a stable pattern to form the behaviour and characteristics of a CA and manage how humans perceive the system. 

Before elaborating on the theory of how humans perceive conversational agents, it is important to understand the background and context of chatbots and conversational agents.

\vspace{5mm} %5mm vertical space

\section{Chatbots and Conversational Agents}

Chatbots are considered to be a form of "weak AI" \citep{DeAngeli2008}, as they are following the stimulus-response approach. They follow scripted rules, and respond from a set of stored, pre-defined responses, and their goal is to simulate human conversation. This approach was first realised with the ELIZA chatbot back in 1966. ELIZA was a conversational agent, written by \cite{Weizenbaum1966}, that acted as a Rogerian psychotherapist. ELIZA was very convincing in its role, and it generated conversation through "using a stimulus-response approach" \citep[: 57]{McTear2016b}. The stimulus-response approach functioned by ELIZA matching the user input against a large set of stored patterns, which informed its response output. ELIZA's role as a psychotherapist was what determined its success in convincingly converse with users; as a psychotherapist can act like she knows almost nothing of the world. When ELIZA extracts a keyword, x, it can respond by saying: "tell me about x". This way of conversing is familiar to how therapist sessions are usually run, and therefore supports users' mental model and expectations when conversing with a therapist. ELIZA inspired future generations of chatbots to simulate human natural language, and ultimately beat Alan Turing's (1950) "Imitation Game": to convince humans that they are conversing with a human, not a machine. Therefore, the history and development of chatbots have always had this goal in mind. Today we see chatbots in education, customer service, e-commerce, as virtual assistants or plainly for entertainment. 

Michael \cite{Mauldin1994} coined the term Chatterbots, which today is known as chatbots, to describe the robots that humans could chat with. Chatbots are conversational agents within the broader term conversation user interfaces (CUI). There are many terms used to describe CUIs such as natural user interfaces (NUI), voice user interfaces (VUI), no user interface or invisible user interface.  CUI and NUI are often used interchangeably, however a NUI often allow for other natural inputs beyond conversation such as touch and gestures. While chatbots refers to CUIs in which users interact with through a chat interface, a VUI only interacts through voice input and output (e.g. Apple's Siri) \citep{Pearl2017}. Other types of conversational interfaces or conversational agents includes spoken dialogue systems (SDS), embodied conversational agents (ECAs) and social robots \citep{McTear2016b}. ECAs make use of facial expressions, animated bodies, and other gestures as well as speech to engage with users. An ECA is therefore a form of a chatbot that make use of more elements than speech to add to the conversation. With the emergence of speech recognition technology and mobile devices, it is common that chatbots also support voice input-output to allow for a more accessible interface.

Conversational agents therefore come in a variety of different forms and purposes, but they all use conversation to interact with humans. Chatbots were originally designed to be conversational partners, rather than a system to help users perform tasks \citep{McTear2016}. Today this definition has changed, as the trends show an increasing rise in the popularity of chatbots as virtual assistants on the web. Companies are rapidly implementing chatbots as an extension of the services they provide to their customers, moving beyond its role as a conversational partner. As stated earlier, a report published by \cite{forrester2017} found that 56 \% of companies either use or plan to implement a chatbot in the near future. The conversational element is used to offer a natural way to interact with brands to retrieve information, service support, product purchasing, or other uses. This trend can be explained by the commercial access to APIs (application programming interfaces) which provides easy access to artificial intelligence (AI) and natural language processing (NLP). In addition to this there is a rise in messaging platforms that supports the hosting of chatbots such as Facebook Messenger, Slack, and Skype among others. Humans have also been introduced to CAs more in their everyday life, as most smartphones offer voice assistants to help manage tasks (e.g. Apple's Siri, Google Assistant, Microsoft Cortana).

This rapid trend has had its downside, as too many of these chatbots perform poorly, and their conversational skills do not meet user expectations \citep{stokke2017,boutin2017}. There is even a website dedicated to inform designers and developers about why most chatbots fail, named chatbot.fail. Recently the Norwegian website DinSide.no reviewed Norwegian customer service chatbots implemented in 2017 and the headline reads: "So Stupid Are the Norwegian Robots" \cite{stokke2017}. The article concludes that Google is more efficient in answering your questions, and more accurate, than the customer service chatbots. The reason for this conclusion is that the user needs to adapt its language for the chatbot to understand their query, which can be a time-consuming process, and the conversational element is missing. Apparently, access to AI and NLP is not what makes or breaks a chatbot, and designers must explore other approaches and techniques to design better conversational interfaces.

\vspace{5mm} %5mm vertical space

\section{Personality to Dictate Human Perception}

%refer to literature review focusing on the most important findings - spend more time talking about how personality can be used
Through the literature review the researcher investigated how humans perceive conversational agents and which factors that can be used to influence human perception. The findings suggests that personality is an important factor in relation to alter and dictate the way in which humans perceive CAs. The following sections will provide a summary of the most important findings from the literature review and why personality is so important to the design of CAs.

\subsection{Emotions and personality}
Emotional intelligence is an important part of how humans perceive themselves as intelligent beings, in order to assess artificial intelligence critics have always used emotional intelligence to define something as a sentient being. Psychologists describe emotional intelligence as the ability to tailor behaviour to environment through necessary emotional processing \citep{callejas2011}. This ability is crucial to conversation, as conversation happen through dynamic relationships between the conversational actors. Therefore, to understand how designers can improve the conversation of chatbots, we must look at these elements of human interaction. The literature review revealed that emotional intelligence is important for humans to perceive CAs as thinking beings as it is part of natural social interactions \citep{Griol2015a,Griol2017,Balzarotti2014,Lemon2012,Mencia2012,McTear2016a}. Research into conversational interfaces and emotion have mostly focused on embodied conversational agents (ECA) \citep{Lester1997,Stern2003, Beun2003,Reeves1996} as the focus has been on the appearance of robots and its emotional responses through body and facial gestures, and its ability to read the "mood" of its conversational partner. Chatbots can make use of the same findings in their design, as these can be used to determine the extent to which a user anthropomorphise a CA.

In human interaction we make use of several social cues that dictates how we behave and how we are perceived by our conversational partners. \cite{Fogg2002} propose that there are five primary social cues: 
\begin{enumerate}
    \item \textbf{Physical:} face, eyes, body, movement
    \item \textbf{Psychological:} preferences, humour, feelings, empathy
    \item \textbf{Language:} interactive language use, spoken language, language recognition
    \item \textbf{Social dynamics:} turn-taking, cooperation, praise, question answering, reciprocity
    \item \textbf{Social Roles:} doctor, teammate, opponent, teacher, pet, guide
\end{enumerate}

Our social interactions are dynamic, in which we mirror and change our behaviour to our conversational partners. Our social role is another important factor that influence how we behave in different situations; we act differently if we take on the role as a parent than we would as a friend. One of the driving forces behind how humans behave as social actors is personality. Our personality can be used to influence our environment, emotions and cognitions as well as our motivations. \cite{callejas2011} listed evidence from empirical research, the psychology of emotional intelligence, and the principle of similarity attraction to explain how personality impacts users perception and willingness to interact with CAs. \cite{Stern2003} found that children interacting with emotional agents or virtual characters forms emotional relationships. There are therefore empirical evidence to support that emotional intelligent agents are more likely to form emotional relationships between the human and the virtual character/agent. 

\cite{callejas2011} and \cite{Xiao2005} believes that personality is the stable pattern that dictates the behaviour of a CA. Personality is defined as a "dynamic and organized set of characteristics possessed by a person that uniquely influences their environment, cognitions, emotions, motivations, and behaviors in various situations" \citep{McTear2016b} (McTear et al., 2016c). Research have found that personality, the characteristics that dictates our behaviour, plays an important part in regards to how users perceive conversational interfaces, and can be the determining factor to whether users wish to interact with the agent again \citep{callejas2011}. \cite{Norman2007} wrote in his book \textit{Emotional Design} that emotional expressions and the personality of things would increase user satisfaction and inform users of what the system is capable of. When designing a conversational agent, the personality can be used to allow for a consistent interaction with the system. As \cite{pavlus2017} Pavlus (2017) states: "in conversational UIs, personality is the new UX". The personality provides users with a consistent interaction, as inconsistent personalities can cause users to feel that they are talking to different "people" in one interaction. When Microsoft's Virtual Assistant Cortana was released with Windows 10, she was described as: "like Siri with a human personality" \citep{beres2015} (Beres, 2015). The PM of Cortana, Susan Hendrich, explained that they had interviewed several celebrities' personal assistants in order to design the right personality users would expect from a personal assistant. The personality of Cortana gave her an edge, that differentiated it from similar available solutions, and by basing her personality on real personal assistants, the design team were able to understand the success criteria of personal assistants (Hendrich, 2017). As chatbots are scripted systems and personality can be used to dictate the behaviour of the CA, personality can also help guide the design process of chatbots and help write the conversation flow and plan for different user scenarios.

\subsection{Anthropomorphism}
Anthropomorphism is defined as "the attribution of human personality or characteristics to something non-human, as an animal, object, etc" (The Oxford Dictionary). Anthropomorphism is therefore human's ability to attribute human motivations, beliefs, and feelings to non-human entities. Researchers have found that anthropomorphism is a normal occurrence in human-computer interaction \citep{Reeves1996,Cohen2004,Pearl2017,Lee2010}, and that personality can be used as a design variable to manage how users anthropomorphise computers \citep{Xiao2005}. According to \cite{Schroeder2016} the "humanlike mind" is an essential component of anthropomorphism, as humans needs to consider the machine as a thinking being to some extent in order for them to perceive the CA as having a mind of its own. While the conversational element is the main element chatbots can make use of in order to simulate a humanlike mind, it is therefore very important that the conversation appear natural and adhere to the rules of social conduct. For ECAs the use of facial gestures, body movements, expressions are important elements in regards to how humans anthropomorphise the agent. Researchers have also found that levels of humanness also affect how humans anthropomorphise, as well as being an important factor for managing trust \citep{Prada2003,Meyer2016,Dautenhahn2002,Terada2015,Epley2007,Lee2004}.

When a human anthropomorphises a computer system or other entity, the humanlike characteristics they attribute to the system is determined by how they perceive the system. Therefore, designers can control how humans attribute characteristics to the CA by designing a personality and use this to guide how it behaves, reacts and how it responds. Through a preliminary study, conducted for the course \textit{IMT4898 Specialisation in Interaction Design}, the researcher found that users anthropomorphised the agent consistently with the predefined personality. The participants were asked to describe the chatbot after having conversed with it, and the words used to describe it matched the predefined personality in which the system was based upon. In this study, the researcher presented participants with the same chatbot personality, however half the participants were presented with a version which had high levels of humanness and the other half with a version with low levels of humanness. The findings from this preliminary study are consistent with findings from other similar experiments where participants rated chatbots according to the personality traits ascribed to it \citep{Holtgraves2007}. However, although users perceived the personality as consistent independent of the levels of humanness, the users did not perceive the two agents equally. The agent with high levels of humanness guided users to engage in natural conversation, while the bot with low levels required more prompts from the moderator to help users interact with it.

\subsection{Humanness}
Humanness is defined as "the extent to which an agent is designed to act and appear human [...] encompassing the objectively established human capabilities (having eyes, a face or the ability to respond politely)" \citep{Meyer2016}. Therefore, researchers distinguish anthropomorphism from humanness as anthropomorphism relates to the psychological attribution of humanlike features \citep{Epley2007,Mori1970,Nass2000}. In simpler terms, humanness refers to the extent the agent looks human through incorporating human appearance and capabilities, while anthropomorphism can be attributed to entities that does not resemble humans in its presentation. This distinction is important, because while anthropomorphism is encouraged, different levels of humanness can have both negative and positive effects on how humans perceives the agent. \cite{Mori1970} coined the term "the uncanny valley" when describing the effects high levels of humanness can have. He found that robots that resembles humans to a very high degree are perceived as creepy, and humans interacting with them feel uncomfortable or fearful of it. Therefore, designers must consider the level of humanness of the agent to not evoke negative emotions. However, although too much humanness can have a negative effect, higher levels of humanness have been found to increase trust.

Visser (in Meyer et al. 2016) states that the degree of humanness should be decided based on the objective. He explained that increased humanness is recommended when the objective is to increase trust, e.g. in systems where errors in automation are more likely to occur. While in systems that deals with situations where users are vulnerable, should have decreased humanness in order to appear more logical, consistent, and fair: without emotion or human judgement (Visser, in Meyer et al, 2016: 281). \cite{Terada2015} found that high levels of humanness had a positive effect on people's buying motivations when CAs were used to recommend products. This they stated might be due to increase in familiarity, as a human form is more familiar in a buying situation, but also because they appeared to be of higher intelligence than agents with low levels of humanness. \cite{Disalvo2002} states that it is important to maintain levels of "robot-ness" to make sure users do not develop false expectations in regards to the capabilities of the agent. If the agent then does not appear to be human when interacting with it, it only looks human, this can cause frustrations and a lack of trust in the system. Examples of CAs with low levels of humanness are Apple's Siri, Microsoft Cortana or Amazon's Alexa, and this is to make it completely clear that these are not human agents and does therefore not possess human characteristics. By keeping this distinction clear humans will treat these CAs as machines rather than humans, and this will manage their expectations towards these systems.

Therefore, while anthropomorphism is encouraged in order to build an emotional relationship between the human and the CA, humanness can be used to determine the extent to which we want humans to anthropomorphise the system. In addition to humanness as a variable, building a consistent personality for the chatbot has been proposed to help manage how the agent is anthropomorphised.

\vspace{5mm} %5mm vertical space

\section{Personality theory}
In order to design a chatbot personality that keeps in line with the chatbot's role and the expectations users might have, designers can consider personality types. Personality, as mentioned earlier in this chapter, is defined as the combination of your behaviour, motivations, characteristics and qualities that forms an individual's character. In short, your personality describes who you are, compared to or distinct from everyone else. While no one person are exactly the same, we can have traits and characteristics in common. Personality theory is the attempt at understanding which factors personalities consists of, and how we can organise these factors into personality types based on which factors we have or have not in common. Carl Jung (1923) coined the term psychology types in which he offered a model to categorise and determine different personality types. His types have since been used to form the bases of type theory, and today there exists several different models to determine personality types, most based on self-evaluation questionnaires. In Jung's (1923) theory, the types are based on attitude types: extroversion vs introversion, and function types: sensation vs intuition, thinking vs feeling. An individual often displays either more extroverted or introverted attitudes, while the functions describe four primary types of psychological functions describing ways in which humans perceive the world. Therefore, he proposed eight types:

\begin{enumerate}
    \item Extroverted or Introverted: sensation-thinking, 
    \item Extroverted or Introverted: sensation-feeling
    \item Extroverted or Introverted: intuition-thinking
    \item Extroverted or Introverted: intuition-feeling
\end{enumerate}

While Jung (1923) proposed the early conceptual theory, Myers and Briggs (2010 [1980]) were the first to offer a type indicator in which one could model personality based on self-assessment. The Myers-Briggs Type Indicator is based on Jung (1923), where they sorted the function types into four dichotomies resulting in sixteen types rather than Jung's eight. These sixteen types are then referred to by four letters. They added the dimension of judgement and perception which describes the individual's preference regarding the other two dimensions, whether they prefer the judging (thinking-feeling) or the perceiving function (sensing-intuition) (Myers and Myers, 2010). Other models of personality types are the Big Five (also known as five-factor model or OCEAN) and HEXACO. The Big Five model, is based on five factors (Toegel and Barsoux, 2012):

\begin{enumerate}
    \item Openness to experience
    \item Conscientiousness
    \item Extroversion
    \item Agreeableness
    \item Neuroticism 
\end{enumerate}

While HEXACO added a sixth dimension (hexaco.org):
\begin{enumerate}
    \item Honesty-Humility
    \item Emotionality
    \item eXtraversion
    \item Agreeableness (versus Anger)
    \item Conscientiousness
    \item Openness to Experience
\end{enumerate}

The Big Five and HEXACO are both based on lexical theories, which uses adjectives in language that describes behaviours and tendencies among individuals. 

The Big Five personality framework is the most widely known and used to model personality. According to \cite{Ackerman2017} \todo{update citations} the Big Five can be applied in multiple countries and cultures, and the assessment scale has been found to be valid and reliable for measuring the five factors. Lewis Goldberg defined the five factor model in the 1960's, and the validity of his model was confirmed by Costa \& McCrae which was named the "Big Five". Each of the five factors includes many traits and characteristics that are related, and organised within each factor. The factors  includes terms on the dimensions from positive to negative, e.g. generosity and aggressiveness, are both included in the agreeableness factor. In the next subsections each factor will be explained, and a few of the traits and characteristics for each factor will be given in order to give a clear idea of what each factor includes. Every personality is the sum of the traits within the five factors, some have more traits belonging in one factor than the other.

\subsection{Openness to Experience}
John \& Srivastava (1999) defined openness to experience as the complexity of an individual's mental life and experiences; a person's willingness to try new things, intellect and imagination. Lebowitz (2016) states that an indivudal that is high in openness to experience engages in creative careers, enjoys getting to know new people, the arts and learning.

\subsection{Conscientiousness}
John \& Srivastava (1999) described conscientiousness as the tendency to control impulses

\subsection{Extroversion}
\subsection{Agreeableness}
\subsection{Neuroticism}


There are therefore several ways in order to model a personality type using these models. The researcher will investigate, through the Master Thesis project, that the chatbot personality type is modelled based on the personality of users as well as the personality type that best describe the role of the chatbot.

\vspace{5mm} %5mm vertical space

\section{Designing chatbot personalities} 
%more on this section - this needs to explain the decisions and cut offs the researcher has done when designing the personality framework.

In order to understand the tools to use in order to design a personality for a chatbot, researchers and designers have offered some insights, models and techniques to base the personality on. Through chatbot forums and communities online, designers suggest basing the chatbot's personality on the users who are going to use it, the brand in which the chatbot represents, and then use techniques from character development in order to write the character. In order to design a personality that is based on the people who are going to interact with it, designers must have access to relevant user information in order to understand the user group. User-centred design methods offer several techniques for designers to build a solid understanding of their users. The most common practice is the development of user personas through user research techniques such as interviews, observation, contextual inquiries or market research \citep{Courage2015}. User personas are defined as "concrete representations of the different types of people that the system or service is being designed for" \citep[: 55]{Benyon2014}. A user persona should always be based on data collected through user research, and often there are more than one persona to represent the entirety of the user group. User personas should include aims and goals for using your system (ibid), and can be used for designers to always remember who they are designing for. The great thing about user personas is that they include, names, age, gender, background, and goals and aspirations, as well as frustrations and tensions related to existing solutions or the context in general. If designers want to design user-centred chatbot personalities, they should mirror the user personas by supporting their goals and aspirations as well as having knowledge related to their frustrations and tensions.

\subsection{The Importance of Social Roles}
Even the best persona is still a broad representation of a user group, and can often be prone to stereotypes. Therefore, as there is usually more than one particular user, the chatbot personality should be designed to not only mirror users, but to fit within its social role. As this can help maintain an appropriate dynamic, even when the user's personality is not a direct match. The social role of a chatbot is determined by its job, the task it carries out and how a person within that role is expected to behave. E.g. a customer service chatbot might bring about very specific expectations in terms of how it conducts itself and treat users. Therefore, by defining the role will provide a lot of information as well as guiding specific areas of the chatbot persona.

\subsection{Brand Tone-of-Voice}

One way that brands successfully communicates a brand personality is through Tone-of-Voice. The tone of voice of brands is used to guide how the company presents itself through all platforms of communication; whether through digital or printed communications, marketing materials, website and more (Cummings, 2017). The brand tone of voice ensures consistency in how the brand is presented, and in particular well-established brands' tone of voice are familiar to consumers. Breaking with their tone of voice can have large implications on how the brand is perceived. The researcher hypothesize that the same is true for chatbot interfaces, and that a well-defined personality and tone-of-voice is important to allow for consistent user experience in which the users perceive the brand through the chatbot. The researcher hypothesize that this will increase trust when brand tone of voice and the chatbot's use of the brand tone of voice offers a familiar and consistent user experience. In branding the concept of tone of voice is used to inform and design a brand image. Cummings (2017) writes: "tone of voice is not what you say, but how you say it". For chatbot design, how they say it is important to communicate the right personality and to meet user expectations. The tone of voice refers to written and spoken words: the words chosen, their order, rhythm and pace (Cummings, 2017). The tone of voice informs a company's written copy, which extends to their website, social media messages, emails and packaging. "A tone of voice both embodies and expresses the brand's personality and set of values" (Cummings, 2017). As the commercial implementation of chatbots are usually as an extension of services companies provide, it would seem that treating a chatbots personality to reflect a company's tone of voice is important to its design. 

Tone of voice matters for the design of conversational interfaces such as chatbots, because tone of voice refers to a linguistic message. While the concept of tone of voice has been used in advertising and marketing as a communication tool towards consumers, tone of voice is also used to convey a company's "personality" (Delin, 2005: 2). Examining the effects of a company's tone of voice relates to the link of familiarity with trust, and being consistent will increase familiarity, and this is why defining a clear tone of voice and using this consistently in all communication with consumers, will increase consumer trust. And according to Cialdini (2007) familiarity is an important tool for persuasion. Norman (2007) makes a point out of how not knowing what to expect when interacting with services, computers, products, or humans, because the behaviour is inconsistent, will make people frustrated and irritated. He therefore stresses the importance of matching personality to market segment to be consistent in interaction with people, as he argues that even if a personality is obnoxious, as long as this is consistent you will know what to expect and therefore plan for it (p. 57). Therefore, tone of voice is one of the most important variables to create a consistent communication between companies and consumers. This is an important idea to understand how personality can be used as variable to plan for different user scenarios and maintain frustration with the system. By applying a personality, the designer will be able to plan ahead to how the chatbot should respond, and also allow users a consistent experience that could help manage expectations.

A chatbot is working 24 hours 7 days a week, and can therefore alleviate customer frustrations, worries, and stress and handle tasks when it suits the consumers; beyond opening hours. Chatbots makes companies more accessible, usable, and can increase user satisfaction. A chatbot can therefore offer great value not only to the services brands offer, but also to consumers. The researcher therefore believes that by creating a framework to design chatbot personalities that incorporates a brand's tone of voice, and offers a consistent user experience, will create more usable chatbot interfaces which benefits both companies and its consumers. This will result in designers making better, informed, user-centred design decisions when designing the chatbot user experience, the interface, and persona, that will result in more users adopting chatbots in their interaction with brands.

\vspace{5mm}

The discussion above shows why personality can be a powerful tool in the design of chatbot interfaces as it can contribute to a more consistent, familiar, trustworthy and satisfactory user experience. The next chapter will show how the reasearcher used this knowledge to form a design framework to build chatbot personalities.





