\chapter{Theory, Background, Existing Literature}
\label{chap:background}

%explain user experience as well - operationalise it - how it will be evaluated. As well as UCD and more on the role of the chatbot

To understand the scope of research related to the interaction between chatbots and humans, and to understand what important factors to consider to design chatbot personalities, the researcher conducted a literature review as part of the course \textit{IMT4215 Specialisation Project}. This review investigated the scope of research as it related to how humans perceive computers that talk, by looking at research related to the effect anthropomorphism, humanness, and personality have on the user experience of conversational interfaces. The review was concerned with theories in human-computer interaction research, while also exploring human-robot interaction, and theories within human factors and psychology. Through this review the researcher found that emotional intelligence, anthropomorphism, humanness, politeness, human etiquette, humour and gender are important variables to consider when designing a CA, as these are important to how users perceive and experience a CA. In addition, the review also found that researchers \citep{callejas2011,Xiao2005,McTear2016a} believe that personality can be used as a stable pattern to form the behaviour and characteristics of a CA and manage how humans perceive the system. Findings from this review will be summarised and discussed in this chapter in addition to the theory and background regarding chatbots, and how personality theory and insights from branding can inform the design of chatbot personalities.

\vspace{5mm} %5mm vertical space

\section{Chatbots and Conversational Agents}

Chatbots are considered to be a form of "weak AI" \citep{DeAngeli2008}, this means that they do not exceed human intelligence and are often used to complete tasks and for analysing and processing information. Chatbots follow scripted rules, and respond from a set of stored, pre-defined responses, with the goal of simulating human language and conversation. This approach, called a "stimulus-response approach" \citep[: 57]{McTear2016b}, was first realised with the ELIZA chatbot back in 1966. ELIZA was a conversational agent, written by \cite{Weizenbaum1966}, that played the role as a Rogerian psychotherapist very convincingly. The stimulus-response approach functioned by ELIZA matching the user input against a large set of stored patterns, which informed its response output. This means that ELIZA makes a prediction in regards to which of its responses matches to the user's query. This approach proved to be very successful for ELIZA's role as a psychotherapist, and made it appear that she was convincingly conversing with users. The same approach is still used today, and there are two different models: retrieval-based models and generative models \citep{Kothari2016}. The first model uses predefined responses, while the generative model can put together new responses based on users' input. The second model is of course much more difficult to implement, while the first model provides control of which responses the chatbot gives and is much quicker and easier to build and implement. Most of the chatbots we see today that are provided by brands, are based on the retrieval-based models. While being more in control of the output of the chatbots in the retrieval-based model, the downside is that they often appear as less intelligent and are prone to errors if they fail to recognise the correct user intention. ELIZA was successful when she conversed with users, because her role as a psychotherapist allowed her to act like she knew nothing of the world \citep{Weizenbaum1966}. The way in which ELIZA conversed, "tell me more about x", appeared familiar and consistent to how therapy sessions are usually run, and therefore supported users' mental model and expectations when conversing with a therapist. ELIZA inspired future generations of chatbots to simulate human natural language, and ultimately beat Alan \cite{Turing1950} "Imitation Game": to convince humans that they are conversing with a human, not a machine. Therefore, the history and development of chatbots have always had this goal in mind. Today we see chatbots in education, customer service, e-commerce, as virtual assistants or plainly for entertainment as recent advances in machine learning allows for more advanced AI and NLP capabilities for chatbots.

Michael \cite{Mauldin1994} coined the term Chatterbots, which today is known as chatbots, to describe the robots that humans could chat with. Chatbots are conversational agents within the broader term conversational user interfaces (CUI). There are many terms used to describe CUIs such as natural user interfaces (NUI), voice user interfaces (VUI), no user interface or invisible user interface.  CUI and NUI are often used interchangeably, however a NUI often allow for other natural inputs beyond conversation such as touch and gestures. While chatbots refers to CUIs in which users interact with through a chat interface, a VUI only interacts through voice input and output (e.g. Apple's Siri) \citep{Pearl2017}. Other types of conversational interfaces or conversational agents includes spoken dialogue systems (SDS), embodied conversational agents (ECAs) and social robots \citep{McTear2016b}. ECAs make use of facial expressions, animated bodies, and other gestures as well as speech to engage with users. An ECA is therefore a form of a chatbot that make use of more elements than speech to add to the conversation. With the emergence of speech recognition technology and mobile devices, it is common that chatbots also support voice input-output to allow for a more accessible interface.

Conversational agents therefore come in a variety of different forms and purposes, but they all use conversation to interact with humans. Chatbots were originally designed to be conversational partners, rather than a system to help users perform tasks \citep{McTear2016a}. Today this definition has changed, as the trends show an increasing rise in the popularity of chatbots as virtual assistants (VA) on the web. Companies are rapidly implementing chatbots as an extension of the services they provide to their customers, moving beyond its role as a conversational partner. As stated earlier, a report published by \cite{forrester2017} found that 57 \% of companies either use or plan to implement a chatbot in the near future. The conversational element is used to offer a natural way to interact with brands to retrieve information, service support, product purchasing, or other uses. This trend can be explained by the commercial access to APIs which provides easy access to AI and NLP. In addition to this there is a rise in messaging platforms that supports the hosting of chatbots such as Facebook Messenger, Slack, and Skype among others. Humans have also been introduced to CAs more in their everyday life, as most smartphones offer voice assistants to help manage tasks (e.g. Apple's Siri, Google Assistant, Microsoft Cortana).

This rapid trend has had its downside, as too many of these chatbots perform poorly, and their conversational skills do not meet user expectations \citep{stokke2017,boutin2017}. Recently the Norwegian website DinSide.no reviewed Norwegian customer service chatbots implemented in 2017 and the headline reads: "So Stupid Are the Norwegian Robots" \cite{stokke2017}. The article concludes that Google is more efficient in answering your questions, and more accurate, than the customer service chatbots. The reason for this conclusion is that the user needs to adapt its language for the chatbot to understand their query, which can be a time-consuming process, and the conversational element is missing. Apparently, access to AI and NLP is not what makes or breaks a chatbot, and designers must explore other approaches and techniques to design better conversational interfaces.

\vspace{5mm} %5mm vertical space

\section{Personality to Dictate Human Perception}
    \label{humanperception}

Through the literature review, the researcher investigated how humans perceive conversational agents and which factors that can be used to influence human perception. The findings suggests that personality is an important factor in relation to alter and dictate the way in which humans perceive CAs. The following sections will provide a summary of the most important findings from the literature review and why personality is so important to the design of CAs.

\vspace{2,5mm}

\subsection{Emotions and personality}
    \label{emotionspersonality}
Emotional intelligence is an important part of how humans perceive themselves as intelligent beings. In order to assess artificial intelligence critics have always used emotional intelligence to define something as a sentient being. Psychologists describe emotional intelligence as the ability to tailor behaviour to environment through necessary emotional processing \citep{callejas2011}. This ability is crucial to conversation, as conversation happen through dynamic relationships between the conversational actors. Therefore, to understand how designers can improve the conversation of chatbots, we must look at these elements of human interaction. The literature review revealed that emotional intelligence is important for humans to perceive CAs as thinking beings as it is part of natural social interactions \citep{Griol2015a,Griol2017,Balzarotti2014,Lemon2012,Mencia2012,McTear2016a}. Research into conversational interfaces and emotion have mostly focused on embodied conversational agents (ECA) \citep{Lester1997,Stern2003, Beun2003,Reeves1996} as the focus has been on the appearance of robots and its emotional responses through body and facial gestures, and its ability to read the "mood" of its conversational partner. Chatbots can make use of the same findings in their design, as these can be used to determine the extent to which a user anthropomorphise (more in section \ref{anthropomorphism}) a CA.

In human interaction we make use of several social cues that dictates how we behave and how we are perceived by our conversational partners. \cite{Fogg2002} propose that there are five primary social cues: 
\begin{enumerate}
    \item \textbf{Physical:} face, eyes, body, movement
    \item \textbf{Psychological:} preferences, humour, feelings, empathy
    \item \textbf{Language:} interactive language use, spoken language, language recognition
    \item \textbf{Social dynamics:} turn-taking, cooperation, praise, question answering, reciprocity
    \item \textbf{Social Roles:} doctor, teammate, opponent, teacher, pet, guide
\end{enumerate}

Our social interactions are dynamic, in which we mirror and change our behaviour to our conversational partners. Our social role is another important factor that influence how we behave in different situations; we act differently if we take on the role as a parent than we would as a friend. One of the driving forces behind how humans behave as social actors is personality. Our personality can be used to influence our environment, emotions and cognitions as well as our motivations. \cite{callejas2011} listed evidence from empirical research, the psychology of emotional intelligence, and the principle of similarity attraction to explain how personality impacts users perception and willingness to interact with CAs. \cite{Stern2003} found that children interacting with emotional agents or virtual characters forms emotional relationships. There are therefore empirical evidence to support that emotional intelligent agents are more likely to form emotional relationships between the human and the virtual character/agent. 

\cite{callejas2011} and \cite{Xiao2005} believes that personality is the stable pattern that dictates the behaviour of a CA. Personality is defined as a "dynamic and organized set of characteristics possessed by a person that uniquely influences their environment, cognitions, emotions, motivations, and behaviors in various situations" \citep{McTear2016b}. Research have found that personality, the characteristics that dictates our behaviour, plays an important part in regards to how users perceive conversational interfaces, and can be the determining factor to whether users wish to interact with the agent again \citep{callejas2011}. \cite{Norman2007} wrote in his book \textit{Emotional Design} that emotional expressions and the personality of things would increase user satisfaction and inform users of what the system is capable of. When designing a conversational agent, the personality can be used to allow for a consistent interaction with the system. As \cite{pavlus2016} states: "in conversational UIs, personality is the new UX". The personality provides users with a consistent interaction, as inconsistent personalities can cause users to feel that they are talking to different "people" in one interaction. When Microsoft's Virtual Assistant Cortana was released with Windows 10, she was described as: "like Siri with a human personality" \citep{beres2015}. The PM of Cortana, Susan Hendrich, explained that they had interviewed several celebrities' personal assistants in order to design the right personality users would expect from a personal assistant. The personality of Cortana gave her an edge, that differentiated it from similar available solutions, and by basing her personality on real personal assistants, the design team were able to understand the success criteria of personal assistants \citep{hendrich2017}. As chatbots are scripted systems and personality can be used to dictate the behaviour of the CA, personality can also help guide the design process of chatbots and help write the conversation flow and plan for different user scenarios.

\vspace{2,5mm}

\subsection{Anthropomorphism}
    \label{anthropomorphism}
Anthropomorphism is defined as "the attribution of human personality or characteristics to something non-human, as an animal, object, etc" \citep{oxd2018}. Anthropomorphism is therefore human's ability to attribute human motivations, beliefs, and feelings to non-human entities. Researchers have found that anthropomorphism is a normal occurrence in human-computer interaction \citep{Reeves1996,Cohen2004,Pearl2017,Lee2010}, and that personality can be used as a design variable to manage how users anthropomorphise computers \citep{Xiao2005}. According to \cite{Schroeder2016} the "humanlike mind" is an essential component of anthropomorphism, as humans needs to consider the machine as a thinking being to some extent in order for them to perceive the CA as having a mind of its own. While the conversational element is the main element chatbots can make use of in order to simulate a humanlike mind, it is therefore very important that the conversation appear natural and adhere to the rules of social conduct. For ECAs the use of facial gestures, body movements, expressions are important elements in regards to how humans anthropomorphise the agent. Researchers have also found that levels of humanness also affect how humans anthropomorphise, as well as being an important factor for managing trust \citep{Prada2003,Meyer2016,Dautenhahn2002,Terada2015,Epley2007,Lee2004}.

When a human anthropomorphises a computer system or other entity, the humanlike characteristics they attribute to the system is determined by how they perceive the system. Therefore, designers can control how humans attribute characteristics to the CA by designing a personality and use this to guide how it behaves, reacts and how it responds. Through a preliminary study, conducted for the course \textit{IMT4898 Specialisation in Interaction Design}, the researcher found that users anthropomorphised the agent consistently with the predefined personality. The participants were asked to describe the chatbot after having conversed with it, and the words used to describe it matched the predefined personality in which the system was based upon. In this study, the researcher presented participants with the same chatbot personality, however half the participants were presented with a version which had high levels of humanness and the other half with a version with low levels of humanness. The findings from this preliminary study are consistent with findings from other similar experiments where participants rated chatbots according to the personality traits ascribed to it \citep{Holtgraves2007}. However, although users perceived the personality as consistent independent of the levels of humanness, the users did not perceive the two agents equally. The agent with high levels of humanness guided users to engage in natural conversation, while the bot with low levels required more prompts from the moderator to help users interact with it.

\vspace{2,5mm}

\subsection{Humanness}
Humanness is defined as "the extent to which an agent is designed to act and appear human [...] encompassing the objectively established human capabilities (having eyes, a face or the ability to respond politely)" \citep{Meyer2016}. Therefore, researchers distinguish anthropomorphism from humanness as anthropomorphism relates to the psychological attribution of humanlike features \citep{Epley2007,Mori1970,Nass2000}. In simpler terms, humanness refers to the extent the agent looks human through incorporating human appearance and capabilities, while anthropomorphism can be attributed to entities that does not resemble humans in its presentation. This distinction is important, because while anthropomorphism is encouraged, different levels of humanness can have both negative and positive effects on how humans perceives the agent. \cite{Mori1970} coined the term "the uncanny valley" when describing the effects high levels of humanness can have. He found that robots that resembles humans to a very high degree are perceived as creepy, and humans interacting with them feel uncomfortable or fearful of it. Therefore, designers must consider the level of humanness of the agent to not evoke negative emotions. However, although too much humanness can have a negative effect, higher levels of humanness have been found to increase trust.

Visser (in Meyer et al. 2016) states that the degree of humanness should be decided based on the objective. He explained that increased humanness is recommended when the objective is to increase trust, e.g. in systems where errors in automation are more likely to occur. While in systems that deals with situations where users are vulnerable, should have decreased humanness in order to appear more logical, consistent, and fair: without emotion or human judgement (Visser, in Meyer et al, 2016: 281). \cite{Terada2015} found that high levels of humanness had a positive effect on people's buying motivations when CAs were used to recommend products. This they stated might be due to increase in familiarity, as a human form is more familiar in a buying situation, but also because they appeared to be of higher intelligence than agents with low levels of humanness. \cite{Disalvo2002} states that it is important to maintain levels of "robot-ness" to make sure users do not develop false expectations in regards to the capabilities of the agent. If the agent then does not appear to be human when interacting with it, it only looks human, this can cause frustrations and a lack of trust in the system. Examples of CAs with low levels of humanness are Apple's Siri, Microsoft Cortana or Amazon's Alexa, and this is to make it completely clear that these are not human agents and does therefore not possess human characteristics. By keeping this distinction clear humans will treat these CAs as machines rather than humans, and this will manage their expectations towards these systems.

Therefore, while anthropomorphism is encouraged in order to build an emotional relationship between the human and the CA, humanness can be used to determine the extent to which we want humans to anthropomorphise the system. In addition to humanness as a variable, building a consistent personality for the chatbot has been proposed to help manage how the agent is anthropomorphised.

\vspace{5mm}

\subsection{Other factors for how humans perceive CAs}
    \label{otherfactors}
\vspace{2.5mm}

\subsubsection{Politeness}
\cite{Meyer2016} proposed in their article that human politeness and etiquette can be used as a variable to design a chatbot’s behaviour. Researchers have found that humans perceive polite agents more positively than those who were less polite or machine like \citep{Inbar2015, Holtgraves2007}. Polite behaviour also provide consistency and meets user’s expectations, as different social roles also dictates behaviour in terms of expected politeness, and this can be enough to achieve desired perceptions. While appearing human can be desired by the designers of chatbots, it is important that human users of the chatbot are aware of what or who they are conversing with. Therefore, if the context in which the chatbot interaction occurs makes it important that users are very aware that they are conversing with a machine; politeness and human etiquette can be used instead of humanness to offer a positive interaction. It is also important to consider social and cultural differences regarding rules of conduct.


\subsubsection{Humour}
Humour has been found to also have a positive effect on how humans perceive chatbots. Humour is an important part of everyday social human interaction \citep{Dirk2003} and can be used to foster engagement. In computer systems in which tasks might be long and boring, humour can be used to maintain long-term interactions and alleviate boredom \citep{McTear2016b}. In addition to this, a chatbot that is humorous might encourage more positive involvement, and increase whether humans perceive it as being emotionally intelligent \citep{Dybala2009}. Humour is therefore a great way to add emotion to a conversation, as chatbots can be trained through computational humour \citep{Augello2011} to recognise humour expressions, user’s mood and emotions, and display appropriate emotions and humour responses in return. Through the preliminary study conducted by the researcher for \textit{IMT4898 Specialisation in Interaction Design}, participants found the use of emojis to be a great way to add humour and emotions to the conversation. They also stated that it helped communicate the chatbots personality in regards to which emojis it used, and how frequently. It is therefore also important to assess the target audience and context to understand whether the use of emojis, and/or jokes, is appropriate.

\subsubsection{Gender}
Which gender to assign to chatbots are problematic in several ways. Through research on CAs and gender, researchers have found that gender have a huge effect on how humans perceive a CA \citep{Zimmerman2005, Brahnam2012, vala2011,  kulms2011}. Female CAs were more likely to be attributed negative stereotypes, and received implicit and explicit sexual attention and swear words \citep{Brahnam2012}. Female ECAs often receive more talk regarding their appearance. The same study found that disembodied female CAs received more attention regarding their appearance than male disembodied CAs, but less than ECAs. In all robotic or androgynous CAs receive much less negative, sexual or profound language than gendered CAs. It is therefore important that those who implement the chatbot also consider whether they should support or break with gender stereotypes, and how the chatbot should handle sexual attention or profound language. 


\vspace{5mm} %5mm vertical space

\section{Personality theory}
In order to design a chatbot personality that keeps in line with the chatbot's role and the expectations users might have, designers can consider personality types. Personality, as mentioned earlier in this chapter, is defined as the combination of your behaviour, motivations, characteristics and qualities that forms an individual's character. In short, your personality describes who you are, compared to or distinct from everyone else. While no one person are exactly the same, we can have traits and characteristics in common. Personality theory is the attempt at understanding which factors personalities consists of, and how we can organise these factors into personality types based on which factors we have or have not in common. Carl \cite{Jung1923} coined the term psychology types in which he offered a model to categorise and determine different personality types. His types have since been used to form the bases of type theory, and today there exists several different models to determine personality types, most based on self-evaluation questionnaires. In \cite{Jung1923} theory, the types are based on attitude types: extroversion vs introversion, and function types: sensation vs intuition, thinking vs feeling. An individual often displays either more extroverted or introverted attitudes, while the functions describe four primary types of psychological functions describing ways in which humans perceive the world. Therefore, he proposed eight types:

\begin{enumerate}
    \item Extroverted or Introverted: sensation-thinking, 
    \item Extroverted or Introverted: sensation-feeling
    \item Extroverted or Introverted: intuition-thinking
    \item Extroverted or Introverted: intuition-feeling
\end{enumerate}

While \cite{Jung1923} proposed the early conceptual theory, \cite{Myers2010}[1980]  were the first to offer a type indicator in which one could model personality based on self-assessment. The Myers-Briggs Type Indicator (MBTI) is based on \cite{Jung1923}, where they sorted the function types into four dichotomies resulting in sixteen types rather than Jung's eight. These sixteen types are then referred to by four letters. They added the dimension of judgement and perception which describes the individual's preference regarding the other two dimensions, whether they prefer the judging (thinking-feeling) or the perceiving function (sensing-intuition) \citep{Myers2010}. Other models of personality types are the Big Five (also known as five-factor model or OCEAN) and HEXACO. The Big Five model, is based on five factors \citep{toegel2012}:

\begin{enumerate}
    \item Openness to experience
    \item Conscientiousness
    \item Extroversion
    \item Agreeableness
    \item Neuroticism 
\end{enumerate}

While HEXACO added a sixth dimension (hexaco.org):
\begin{enumerate}
    \item Honesty-Humility
    \item Emotionality
    \item eXtraversion
    \item Agreeableness (versus Anger)
    \item Conscientiousness
    \item Openness to Experience
\end{enumerate}

The Big Five and HEXACO are both based on lexical theories, which uses adjectives in language that describes behaviours and tendencies among individuals. 

\vspace{2.5mm} %5mm vertical space

\subsection{The Big Five}

The Big Five "provides a descriptive taxonomy that organizes the myriad natural-language and scientific trait concepts into a single classifactory framework" \citep{John1999}. The Big Five personality framework is the most widely known and used framework to model personality. According to \cite{Ackerman2017} the Big Five can be applied in multiple countries and cultures, and the assessment scale has been found to be valid and reliable for measuring the five factors. Lewis Goldberg defined the five factor model in the 1960's, and the validity of his model was confirmed by \cite{mccrae1987} which was named the "Big Five". Each of the five factors includes many traits and characteristics that are related, and organised within each factor. The factors  includes terms on the dimensions from positive to negative, e.g. generosity and aggressiveness, are both included in the agreeableness factor. In the next subsections each factor will be explained, and a few of the traits and characteristics for each factor will be given in order to give a clear idea of what each factor includes. Every personality is the sum of the traits within the five factors, some have more traits belonging in one factor than the other. \cite{John1999} found that the labels for each of the five factors are often misunderstood, as the labels themselves are not correctly describing the traits, they therefore sought to create short definition to avoid confusion and misunderstandings.

\subsubsection{Openness to Experience}

\begin{quote}
    "Openness to Experience (versus closed-mindedness) describes the breadth, depth, originality and complexity of an individual's \textit{mental and experiential life}" \citep[p.121]{John1999}.
\end{quote}

\cite{John1999} defined openness to experience as the complexity of an individual's mental life and experiences; a person's willingness to try new things, inquiring intellect and imagination. \cite{Lebowitz2016} states that an individual that is high in openness to experience engages in creative careers, enjoys getting to know new people, the arts and learning.

\subsubsection{Conscientiousness}
\begin{quote}
    "Conscientiousness describes \textit{socially prescribed impulse control} that facilitates task- and goal-directed behavior, such as thinking before acting, delaying gratification, following norms and rules, and planning, organizing, and prioritizing tasks" \citep[p.121]{John1999}.
\end{quote}

Conscientious individuals have the tendency to control impulses, have the will to achieve, are hard-working and rule-followers.

\subsubsection{Extroversion}
\begin{quote}
    "Extroversion implies an \textit{energetic approach} to the social and material world and includes traits such as sociability, activity, assertiveness, and positive emotionality" \citep[p.121]{John1999}.

\end{quote}

The factor Extroversion includes two ends of the spectrum: Extroversion \& Introversion. Extroverted individuals draws energy from interacting with people, while introverted individuals will become tired from social interactions and draws energy from solitude.

\subsubsection{Agreeableness}
\begin{quote}
    "Agreeableness contrasts a \textit{prosocial and communal orientation} toward others with antagonism and includes traits such as altruism, tender-mindedness, trust, and modesty" \citep[p.121]{John1999}.
\end{quote}

Agreeableness can be explained by how likely you are to be liked by people around you, or how well you get along with others. Also known as social adaptability, likeability, friendly compliance, and includes traits such as: polite, humble, trusting, modest, loyal, unselfish, amiable, and cheerful.

\subsubsection{Neuroticism}
\begin{quote}
    "Neuroticism contrasts emotional stability and even-temperedness with \textit{negative emotionality}, such as feeling anxious, nervous, sad, and tense" \citep[p.121]{John1999}.
\end{quote}

Neuroticism is the factor where a high score indicates more negative traits, while the other factors where individuals have high scores indicate more positive traits. Neuroticism is a factor which explains how comfortable you are in your own skin or how confident you are.

\vspace{2,5mm}

While this has been a short and concise introduction to personality theory and the big five, it describes the most important general understanding of the framework. This understanding of the five factors, and the traits which each consists of, will be used to guide the design of the chatbot personality.

\vspace{5mm} %5mm vertical space

\section{Designing chatbot personalities} 
%more on this section - this needs to explain the decisions and cut offs the researcher has done when designing the personality framework.

In order to understand the tools to use in order to design a personality for a chatbot, researchers and designers have offered some insights, models and techniques to base the personality on. Through chatbot forums and communities online, designers suggest basing the chatbot's personality on the users who are going to use it, the brand in which the chatbot represents, and then use techniques from character development in order to write the character. In order to design a personality that is based on the people who are going to interact with it, designers must have access to relevant user information in order to understand the user group. User-centred design methods offer several techniques for designers to build a solid understanding of their users. The most common practice is the development of user personas through user research techniques such as interviews, observation, contextual inquiries or market research \citep{Courage2015}. User personas are defined as "concrete representations of the different types of people that the system or service is being designed for" \citep[: 55]{Benyon2014}. A user persona should always be based on data collected through user research, and often there are more than one persona to represent the entirety of the user group. User personas should include aims and goals for using your system (ibid), and can be used for designers to always remember who they are designing for. The great thing about user personas is that they include, names, age, gender, background, and goals and aspirations, as well as frustrations and tensions related to existing solutions or the context in general. If designers want to design user-centred chatbot personalities, they should mirror the user personas by supporting their goals and aspirations as well as having knowledge related to their frustrations and tensions.

\vspace{2,5mm}

\subsection{The Importance of Social Roles}
Even the best persona is still a broad representation of a user group, and can often be prone to stereotypes. Therefore, as there is usually more than one particular user, the chatbot personality should be designed to not only mirror users, but to fit within its social role. As this can help maintain an appropriate dynamic, even when the user's personality is not a direct match. When humans enters a specific social role it sets expectations and goals for the interaction, as mentioned earlier in section \ref{emotionspersonality}, and the role and social conduct becomes more important. The social role of a chatbot is determined by its job, the task it carries out and how a person within that role is expected to behave. E.g. a customer service chatbot might bring about very specific expectations in terms of how it conducts itself and treat users. Therefore, by defining the role will provide a lot of information as well as guiding specific areas of the chatbot persona.

\vspace{2,5mm}

\subsection{Brand Tone-of-Voice}

One way that brands successfully communicates a brand personality is through Tone-of-Voice. The tone of voice of brands is used to guide how the company presents itself through all platforms of communication; whether through digital or printed communications, marketing materials, website and more \citep{cummings2017}. The brand tone of voice ensures consistency in how the brand is presented, and in particular well-established brands' tone of voice are familiar to consumers. Breaking with their tone of voice can have large implications on how the brand is perceived. The researcher hypothesize that the same is true for chatbot interfaces, and that a well-defined personality and tone-of-voice is important to allow for consistent user experience in which the users perceive the brand through the chatbot. The researcher believes that this will increase trust as the brand tone of voice and the chatbot's use of it will contribute to a more familiar and consistent user experience. In branding the concept of tone of voice is used to inform and design a brand image. \cite{cummings2017} writes: "tone of voice is not what you say, but how you say it". For chatbot design, how they say it is important to communicate the right personality and to meet user expectations. The tone of voice refers to written and spoken words: the words chosen, their order, rhythm and pace \citep{cummings2017}. The tone of voice informs a company's written copy, which extends to their website, social media messages, emails and packaging. "A tone of voice both embodies and expresses the brand's personality and set of values" \citep{cummings2017}. As the commercial implementation of chatbots are usually as an extension of services companies provide, it would seem that treating a chatbots personality to reflect a company's tone of voice is important to its design. 

Tone of voice matters for the design of conversational interfaces such as chatbots, because tone of voice refers to a linguistic message. While the concept of tone of voice has been used in advertising and marketing as a communication tool towards consumers, tone of voice is also used to convey a company's "personality" \citep[: 2]{delin2005}. Examining the effects of a company's tone of voice relates to the link of familiarity with trust, and being consistent will increase familiarity, and this is why defining a clear tone of voice and using this consistently in all communication with consumers, will increase consumer trust. And according to \cite{cialdini2007} familiarity is an important tool for persuasion. \cite{Norman2007} makes a point out of how not knowing what to expect when interacting with services, computers, products, or humans, because the behaviour is inconsistent, will make people frustrated and irritated. He therefore stresses the importance of matching personality to market segment to be consistent in interaction with people, as he argues that even if a personality is obnoxious, as long as this is consistent you will know what to expect and therefore plan for it (p. 57). Therefore, tone of voice is one of the most important variables to create a consistent communication between companies and consumers. This is an important idea to understand how personality can be used as a variable to plan for different user scenarios and maintain frustration with the system. By applying a personality, the designer will be able to plan ahead to how the chatbot should respond, and also allow users a consistent experience that could help manage expectations.

A chatbot is working 24 hours 7 days a week, and can therefore alleviate customer frustrations, worries, and stress and handle tasks when it suits the consumers; beyond opening hours. Chatbots makes companies more accessible, usable, and can increase user satisfaction. A chatbot can therefore offer great value not only to the services brands offer, but also to consumers. The researcher therefore believes that by creating a framework to design chatbot personalities that incorporates a brand's tone of voice, and offers a consistent user experience, will create more usable chatbot interfaces which benefits both companies and its consumers. This will result in designers making better, informed, user-centred design decisions when designing the chatbot user experience, the interface, and personality, that will result in more users adopting chatbots in their interaction with brands.

\vspace{5mm}

The discussion above shows why personality can be a powerful tool in the design of chatbot interfaces as it can contribute to a more consistent, familiar, trustworthy and satisfactory user experience. The next chapter will show how the researcher used this knowledge to form a design framework to build chatbot personalities.





