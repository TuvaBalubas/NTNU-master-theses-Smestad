\chapter{Discussion}
\label{chap:discussion}

The results you have collected and the process you when through to develop the project have been presented earlier.  This Chapter is used to talk about your interpretations of results or the process.  It might be a discussion of the language you used.  A tool that you started to use but then stopped using for some reason.  It could give insight into the evolution of your process.

There was only one word-pair in which Chatbot B scored higher than Chatbot A \textit{unprofessional-professional}, where the mean score for Chatbot A was 5,875 and Chatbot B mean score was 6,25. This shows that a machine like and technical Chatbot B were perceived as conducting itself to a higher professional standard than Chatbot A, ever so slightly.

\subsection{Regarding Facebook and the Cambridge Analytica scandal}

Because of the Facebook and Cambridge Analytica scandal during the spring of 2018; Facebook stopped reviewing any third party applications running through their platform. This resulted in the Chatbot B prototype not being able to be published through the messenger platform in time for the experiments. Chatbot A was able to be published through an existing application already reviewed by Facebook before the scandal, however the name of the chatbot was unable to be changed in time of the experiment.

\subsection{Possible confounders}
Because Facebook stopped reviewing new third party applications during the experiment, Chatbot B did not display a profile picture, but instead the chatfuel logo, and the name was displayed as "Chatfuel-test your bot", as this had to be tested through the unpublished test service provided by Chatfuel, rather than being run through its own page and account. Chatbot A however was runned through its own page and account, but the name of the chatbot belonged to a previous version of a chatbot displaying the wrong name. The absence of an image and name for Chatbot B could have impacted how users perceived this chatbot. Some unconsciously referred to this chatbot as a "he" rather than "she" for Chatbot A - even though all participants were instructed before beginning the tests that they are about to test two versions of the chatbot "Bella". The cards each participants used during the test had Bella's face on them in order to remind them of who they are talking to. 

Another possible confounder was one that the researcher failed to recognise before during the testing. This was the recipes suggested by the chatbot. A few of the test participants told the researcher after the experiment had finished, that they rated e.g. the word pair \textit{inventive-conventional} higher because the recipes in themselves were inventive - or they rated the characteristic helpful lower because they did not like the recipes suggested to them. The participants were not instructed to assess the personality of the chatbot, but the chatbot as a product in its entirety, therefore a few of the word-pairs assessed in the AttrakDiff measurement tool might be seen as negative for a product, but positive for a personality e.g. \textit{undemanding-challenging}, were \textit{challenging} was seen as a negative trait to describe the agent by some while for the assessment of a product it is seen as a positive trait. Another word-pair that confused participants were \textit{separates me from people - brings me closer to people}, as a lot of participants noted that talking to a robot would in the long run separate them from people rather than bringing them closer.


\section{Future research}

Use the agree framework more actively when testing the personality. The framework is built on participants interacting with a chatbot in a series of interactions where there is a change in attitude (e.g. unfriendly, neutral, friendly). Instead of testing the change in attitude in this project, participants will instead be asked to rate on a Likert scale to what extent they perceived the specific traits.
