% Encoding: UTF-8

@InCollection{Augello2014,
  author    = {Augello, Agnese and Pilato, Giovanni and Vassallo, Giorgio and Gaglio, Salvatore},
  title     = {Chatbots as Interface to Ontologies},
  booktitle = {Advances onto the Internet of Things: How Ontologies Make the Internet of Things Meaningful},
  year      = {2014},
  editor    = {Gaglio, Salvatore and Lo Re, Giuseppe},
  publisher = {Springer International Publishing},
  pages     = {285--299},
  doi       = {10.1007/978-3-319-03992-3_20},
  url       = {https://doi.org/10.1007/978-3-319-03992-3_20},
  abstract  = {Chatbots are simple conversational agents using “pattern matching rules” to carry out the dialogue with the user and various expedients to improve their credibility. However, the rules on which they are based on are too restrictive and their language understanding capability is very limited. Nevertheless chatbots are widespread in several applications, especially to provide information to users in a new and enjoyable way. In this chapter we describe different chatbot architectures, exploiting the use of ontologies in order to create clever information suppliers overcoming the main limits of chatbots: the knowledge base building and the rigidness of the dialogue mechanism.},
  address   = {Cham},
}

@Article{Balzarotti2014,
  author   = {Balzarotti, Stefania and Piccini, Luca and Andreoni, Giuseppe and Ciceri, Rita},
  title    = {“I Know That You Know How I Feel”: Behavioral and Physiological Signals Demonstrate Emotional Attunement While Interacting with a Computer Simulating Emotional Intelligence},
  journal  = {Journal of Nonverbal Behavior},
  year     = {2014},
  date     = {September 01},
  volume   = {38},
  number   = {3},
  pages    = {283--299},
  doi      = {10.1007/s10919-014-0180-6},
  url      = {https://doi.org/10.1007/s10919-014-0180-6},
  abstract = {Human–human communication studies have suggested that within communicative interactions, individuals acknowledge each other as intentional agents and adjust their emotion nonverbal behavior according to the other. This process has been defined as emotional attunement. In this study, we examine the emotional attunement process in the context of affective human–computer interactions. To this purpose, participants were exposed to one of two conditions. In one case, they played with a computer that simulated understanding of their emotional reactions while guiding them across four different game-like activities; in the other, the computer guided participants across the activities without mentioning any ability to understand emotional responses. Face movements, gaze direction, posture, vocal behavior, electrocardiogram and electrodermal activity were simultaneously recorded during the experimental sessions. Results showed that if participants were aware of interacting with an agent able to recognize their emotions, they reported that the computer was able to “understand” them and showed a higher number of nonverbal behaviors during the most interactive activity. The implications are discussed.},
}

@Article{Lai2000,
  author    = {Lai, Jennifer},
  title     = {Conversational interfaces},
  journal   = {Commun. ACM},
  year      = {2000},
  volume    = {43},
  number    = {9},
  pages     = {24--27},
  doi       = {10.1145/348941.348971},
  publisher = {ACM},
}

@InProceedings{Vandenberghe2017,
  author    = {Vandenberghe, Bert},
  title     = {Bot Personas as Off-The-Shelf Users},
  booktitle = {Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
  year      = {2017},
  publisher = {ACM},
  pages     = {782--789},
  doi       = {10.1145/3027063.3052767},
  address   = {Denver, Colorado, USA},
}

@Book{Lemon2012,
  author    = {Lemon, Oliver and Pietquin, Olivier and service), SpringerLink (Online},
  title     = {Data-Driven Methods for Adaptive Spoken Dialogue Systems : Computational Learning for Conversational Interfaces},
  year      = {2012},
  publisher = {Springer New York : Imprint: Springer},
  abstract  = {One of the first books to specifically address adaptive techniques used in dialogue system development Practical examples developed by the editors and colleagues will be included The book will be based on dialogue systems freely available for academic use},
  comment   = {""Data-Driven Methods for Adaptive Spoken Dialogue Systems""; ""Acknowledgements""; ""Contents""; ""Contributors""; ""Chapter 1: Conversational Interfaces""; ""1.1 Structure of the Book""; ""Chapter 2: Developing Dialogue Managers from Limited Amounts of Data""; ""2.1 Introduction""; ""2.2 Background: Reinforcement Learning for SDS Policy Optimisation""; ""2.2.1 Feature-Based State Representations""; ""2.2.2 Generalisation Methods""; ""2.3 Data Sets""; ""2.3.1 Data Requirements for Learning RL-Based Policies""; ""2.3.2 Existing Data Sets""},
  issn      = {1-4614-4803-4},
  journal   = {Data-Driven Methods for Adaptive Spoken Dialogue Systems},
  keywords  = {Computational Learning, Computational linguistics, Computer science, Computer simulation, Conversation -- Data processing, Natural language processing (Computer science), Speech processing systems, Electrical & Computer Engineering, Engineering & Applied Sciences, Computer Science, Electrical Engineering, Electronic books},
  refid     = {BIBSYS_ILS71524878680002201},
}

@Other{Griol2015,
  author   = {Griol, David and Molina, José Manuel and Callejas, Zoraida},
  title    = {Towards emotionally sensitive conversational interfaces for e-therapy},
  year     = {2015},
  issn     = {9783319189130},
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Adaptation, Conversational Interfaces, Dialog Systems, E-Therapy, Emotion Recognition, Mobile Interfaces, Spoken Interaction},
  pages    = {498--507},
  refid    = {TN_scopus2-s2.0-84937510902},
  volume   = {9107},
}

@Book{McTear2016,
  author    = {McTear, Michael and Callejas, Zoraida and Griol, David and service), SpringerLink (Online},
  title     = {The Conversational Interface : Talking to Smart Devices},
  year      = {2016},
  publisher = {Springer International Publishing : Imprint: Springer},
  abstract  = {This book provides a comprehensive introduction to the conversational interface, which is becoming the main mode of interaction with virtual personal assistants, smart devices, various types of wearables, and social robots. The book consists of four parts: Part I presents the background to conversational interfaces, examining past and present work on spoken language interaction with computers
Part II covers the various technologies that are required to build a conversational interface along with practical chapters and exercises using open source tools
Part III looks at interactions with smart devices, wearables, and robots, and then goes on to discusses the role of emotion and personality in the conversational interface
Part IV examines methods for evaluating conversational interfaces and discusses future directions. · Presents a comprehensive overview of the various technologies that underlie conversational user interfaces
· Combines descriptions of conversational user interface technologies with a guide to various toolkits and software that enable readers to implement and test their own solutions
· Provides a series of worked examples so readers can develop and implement different aspects of the technologies.},
  comment   = {Introduction -- Part 1: Conversational Interfaces: Preliminaries -- The Dawn of the Conversational Interface -- Towards a Technology of Conversation -- Conversational Interfaces: Past and Present -- Part 2: Developing a Speech-Based Conversational Interface -- Speech Input and Output -- Implementing Speech Input and Output -- Creating a Conversational Interface using Chatbot Technology -- Spoken Language Understanding -- Implementing Spoken Language Understanding -- Dialog Management -- Implementing Dialog Management -- Response Generation -- Part 3: Conversational Interfaces and Devices -- Conversational Interfaces: Devices, Wearables, Virtual Agents, and Robots -- Emotion, Affect, and Personality -- Affective Conversational Interfaces -- Implementing Multimodal Conversational Interfaces Using Android Wear -- Part 4: Evaluation and Future Directions -- Evaluation -- Future Directions.},
  issn      = {3-319-32967-7},
  journal   = {Conversational Interface},
  keywords  = {Engineering, User interfaces (Computer systems), Computational linguistics, Engineering, Signal, Image and Speech Processing, User Interfaces and Human Computer Interaction, Language Translation and Linguistics, Electronic books},
  refid     = {BIBSYS_ILS71537176880002201},
}

@Article{Griol2017,
  author  = {Griol, D. and Molina, Jm and Sanchis, A.},
  title   = {Integration of context-aware conversational interfaces to develop practical applications for mobile devices},
  journal = {Journal Of Ambient Intelligence And Smart Environments},
  year    = {2017},
  volume  = {9},
  number  = {5},
  pages   = {561--577},
  issn    = {1876-1364},
  refid   = {TN_wos000407718500004},
}

@Book{Pearl2017,
  author    = {Pearl, Cathy},
  title     = {Designing Voice User Interfaces: Principles of Conversational Experiences},
  year      = {2017},
  publisher = {O'Reilly},
  abstract  = {Your app may allow users to ask Siri about the weather, or ask Google which mountain is the tallest. But how can you design a voice interface for your mobile app so that users can talk to it? And not just to facilitate question-and-answer sessions, but also provide an engaging, compelling experience? With this practical guide, you'll learn basic voice user interface (VUI) principles for designing mobile apps that makes speech an important tool for interaction. You'll learn how to choose the right speech recognition engine, use best methods for testing VUI on mobile, and dive into advanced VUI design topics to make your VUI not just functional but great. Ideal for product managers, UX designers, and VUI designers, this book explains basic VUI principles for mobile app design, and shows you how to measure the performance of your VUI app and improve upon it. You'll also learn how to determine whether using voice for your app is a good idea in the first place VUI design is not just about making things cool-it's about making a user's experience more natural, more powerful, and more human.},
  comment   = {Your app may allow users to ask Siri about the weather, or ask Google which mountain is the tallest. But how can you design a voice interface for your mobile app...},
  issn      = {1491955414},
  keywords  = {Automatic speech recognition},
  refid     = {TN_dawson9781491955383},
}

@Book{Amores2011,
  author   = {Amores, J. and Manchón, Pilar and Pérez, Guillermo},
  title    = {Humanizing Conversational Agents},
  year     = {2011},
  pages    = {312--334},
  abstract = {This chapter describes an eHealth human-like conversational agent called Maria embedded in the Web page of the Health Department of the Junta de Andalucía in Spain. Although this implementation is based on a strong theoretical background, a more practical approach has been preferred for the real-world case hereby described. Maria has been designed to perform several major tasks: she can arrange a doctor’s appointment, reply to queries pertaining to many varied subdomains, and navigate through the Web page. One of Maria’s most remarkable features is the successful application of advanced design and humanizing techniques which endow her with unusual skills and an enticing personality. Maria has been developed by Intelligent Dialogue Systems (Indisys) within a larger scale Web development project conducted by Sadiel SA.},
  comment  = {This chapter describes an eHealth human-like conversational agent called Maria embedded in the Web page of the Health Department of the Junta de Andalucía in Spain. Although this implementation is based on a strong theoretical background, a more practical approach has been preferred for the real-world case hereby described. Maria has been designed to perform several major tasks: she can arrange a doctor’s appointment, reply to queries pertaining to many varied subdomains, and navigate through the Web page. One of Maria’s most remarkable features is the successful application of advanced design and humanizing techniques which endow her with unusual skills and an enticing personality. Maria has been developed by Intelligent Dialogue Systems (Indisys) within a larger scale Web development project conducted by Sadiel SA.},
  issn     = {978-1-60960-617-6},
  refid    = {TN_igiglobal10.4018/978-1-60960-617-6.ch014},
}

@Article{QUARTERONI2009,
  author   = {QUARTERONI, S. and MANANDHAR, S.},
  title    = {Designing an interactive open-domain question answering system},
  journal  = {Natural Language Engineering},
  year     = {2009},
  volume   = {15},
  number   = {1},
  pages    = {73--95},
  issn     = {1351-3249},
  abstract = {Abstract Interactive question answering (QA), where a dialogue interface enables follow-up and clarification questions, is a recent although long-advocated field of research. We report on the design and implementation of YourQA, our open-domain, interactive QA system. YourQA relies on a Web search engine to obtain answers to both fact-based and complex questions, such as descriptions and definitions. We describe the dialogue moves and management model making YourQA interactive, and discuss the architecture, implementation and evaluation of its chat-based dialogue interface. Our Wizard-of-Oz study and final evaluation results show how the designed architecture can effectively achieve open-domain, interactive QA.},
  comment  = {Abstract Interactive question answering (QA), where a dialogue interface enables follow-up and clarification questions, is a recent although long-advocated field of research. We report on the design and implementation of YourQA, our open-domain, interactive QA system. YourQA relies on a Web search engine to obtain answers to both fact-based and complex questions, such as descriptions and definitions. We describe the dialogue moves and management model making YourQA interactive, and discuss the architecture, implementation and evaluation of its chat-based dialogue interface. Our Wizard-of-Oz study and final evaluation results show how the designed architecture can effectively achieve open-domain, interactive QA.},
  keywords = {Question Answer Sequences (69920), Human Computer Communication (32790), Natural Language Generation (56520), Artificial Intelligence (04800), Computer Applications (14150), Descriptive Linguistics, Computational and Mathematical Linguistics, Article;},
  refid    = {TN_cambridgeS1351324908004919},
}

@Other{Ozeki2008,
  author   = {Ozeki, Motoyuki and Maeda, Shunichi and Obata, Kanako and Nakamura, Yuichi},
  title    = {Virtual assistant: an artificial agent for enhancing content acquisition: how ambient media elicit information from humans},
  year     = {2008},
  abstract = {<p><p>In this paper, we propose a novel framework "Virtual Assistant" for enhancing content potentially procured by ambient media. The Virtual Assistant is an artificial agent simulating a human assistant shown in TV programs and prompts users to provide feedback by asking questions or back-channeling. This framework ensures that sufficient information is provided in the captured content while users interact in a natural and enjoyable way with the agent. We developed a prototype agent based on a chatbot-like approach and applied it to a daily cooking scene. The experimental results demonstrate a good potential of the Virtual Assistant framework, allowing a person to provide feedback easily with few interruptions, lifting the face towards the camera, and eliciting a variety of useful information.</p></p>},
  comment  = {In this paper, we propose a novel framework "Virtual Assistant" for enhancing content potentially procured by ambient media. The Virtual Assistant is an artificial agent simulating a human assistant shown in TV programs and prompts users to provide feedback by asking questions or back-channeling. This framework ensures that sufficient information is provided in the captured content while users interact in a natural and enjoyable way with the agent. We developed a prototype agent based on a chatbot-like approach and applied it to a daily cooking scene. The experimental results demonstrate a good potential of the Virtual Assistant framework, allowing a person to provide feedback easily with few interruptions, lifting the face towards the camera, and eliciting a variety of useful information.},
  issn     = {9781605583143},
  keywords = {Ambient Media, Artificial Agent, Content Acquisition},
  pages    = {75--82},
  refid    = {TN_acm1461927},
  series   = {SAME '08},
}

@Article{Salichs2016,
  author   = {Salichs, Miguel and Encinar, Irene and Salichs, Esther and Castro-González, Álvaro and Malfaz, María},
  title    = {Study of Scenarios and Technical Requirements of a Social Assistive Robot for Alzheimer’s Disease Patients and Their Caregivers},
  journal  = {Int J of Soc Robotics},
  year     = {2016},
  volume   = {8},
  number   = {1},
  pages    = {85--102},
  issn     = {1875-4791},
  abstract = {Robots have begun to assist elders and patients suffering dementia. In particular, recent studies have shown how robots can benefit Alzheimer’s disease (AD) patients. This is a novel area with a promising future but lot of researching needs to be done. The RobAlz project is aimed to assist AD patients and their caregivers by social robots. This project is divided in three phases: the definition of the requirements and scenarios, the development of a new robotic platform, and the evaluation. This work presents the results obtained in the first phase, in which several meetings were conducted with a set of subject-matter experts in the areas of Alzheimer’s Disease and social robotics. The meetings were classified according to the application areas they covered: general aspects, safety, entertainment, personal assistance, and stimulation. The meetings ended up with a repertory of scenarios where robots can be applied to Alzheimer’s patients and their caregivers at their home or in longterm care facilities. These scenarios present different psychological, social and technical concerns that must be addressed for the design of the robot. In this work we perform an analysis on the scenarios and present the technical requirements for the development of a first robotic prototype. This prototype will be constructed and tested in real environments in the subsequent phases of the RobAlz project.},
  address  = {Dordrecht},
  comment  = {Robots have begun to assist elders and patients suffering dementia. In particular, recent studies have shown how robots can benefit Alzheimer’s disease (AD) patients. This is a novel area with a promising future but lot of researching needs to be done. The RobAlz project is aimed to assist AD patients and their caregivers by social robots. This project is divided in three phases: the definition of the requirements and scenarios, the development of a new robotic platform, and the evaluation. This work presents the results obtained in the first phase, in which several meetings were conducted with a set of subject-matter experts in the areas of Alzheimer’s Disease and social robotics. The meetings were classified according to the application areas they covered: general aspects, safety, entertainment, personal assistance, and stimulation. The meetings ended up with a repertory of scenarios where robots can be applied to Alzheimer’s patients and their caregivers at their home or in longterm care facilities. These scenarios present different psychological, social and technical concerns that must be addressed for the design of the robot. In this work we perform an analysis on the scenarios and present the technical requirements for the development of a first robotic prototype. This prototype will be constructed and tested in real environments in the subsequent phases of the RobAlz project.},
  keywords = {Alzheimer, Dementia, Elderly, Social assistive robot, Social robot, Assistive robot},
  refid    = {TN_springer_jour10.1007/s12369-015-0319-6},
}

@Other{2017,
  title    = {Lounge Lizard New York Website Design, Shares Chatbot Implementation Tips that will Improve Your UX},
  year     = {2017},
  journal  = {PR Newswire},
  keywords = {Web Site Design - Maintenance and Repair},
  refid    = {TN_gale_ofa501710505},
}

@Book{Catizone2011,
  author   = {Catizone, Roberta and Wilks, Yorick},
  title    = {The Future of Companionable Agents},
  year     = {2011},
  pages    = {379--394},
  abstract = {COMPANIONS is a concept that aims to change the way we think about the relationships of people to computers and the Internet by developing a virtual ’Companion’ to stand between individuals and the torrent of data on the Internet, including their own life information, which will soon be too large for people to handle easily without some new form of assistance. The Companion is intended as an agent or ’presence’ that stays with a user for periods of time, longer than in conventional task-based dialogue systems, developing a relationship and ’knowing’ and assisting its owner’s experiences, preferences, plans, and wishes. The Companions concept aims to model a fuller range of conversation than has been done hitherto, both task and non-task based, and discusses what properties people will want in a long term computer Companion that is also an Internet agent in a new form.},
  comment  = {COMPANIONS is a concept that aims to change the way we think about the relationships of people to computers and the Internet by developing a virtual ’Companion’ to stand between individuals and the torrent of data on the Internet, including their own life information, which will soon be too large for people to handle easily without some new form of assistance. The Companion is intended as an agent or ’presence’ that stays with a user for periods of time, longer than in conventional task-based dialogue systems, developing a relationship and ’knowing’ and assisting its owner’s experiences, preferences, plans, and wishes. The Companions concept aims to model a fuller range of conversation than has been done hitherto, both task and non-task based, and discusses what properties people will want in a long term computer Companion that is also an Internet agent in a new form.},
  issn     = {978-1-60960-617-6},
  refid    = {TN_igiglobal10.4018/978-1-60960-617-6.ch017},
}

@Other{Ginsburg2002,
  author   = {Ginsburg, Mark},
  title    = {The catacomb project: building a user-centered portal the conversational way},
  year     = {2002},
  abstract = {<p>Enterprise computing is marked by large-scale information systems, such as databases, document management, and groupware that present significant obstacles to consistent cross-application use: dissimilar user interfaces, incompatible security schemes, and the undesirable property of serving only parts of the user community (islands of use) and accessing only some of the enterprise knowledge assets (islands of information).World Wide Web (WWW) architectures do not solve this problem directly. WWW software components are combinable in many clever ways but until recently there were no specific efforts to solve the enterprise computing problems of islands of use and information.The situation is changing now with nascent efforts to architect Web Portal systems with small software modules, for example with Java "portlets" or the Python-based Zope framework [15]. These are program-centric approaches to coalesce information sources and unify the query interface without inherent user modeling. This paper discusses in detail an alternative: a user-centered, conversational portal which extends the ALICE chatbot technology platform and links the user conveniently to information resources, such as Web Services, with specialized query routing. The approach offers scalability, extensibility, and coordination between end-users and developers. A university Intranet implementation, the Catacomb system, is presented and discussed to illustrate the advantages of the conversational Web portal approach.</p>},
  comment  = {Enterprise computing is marked by large-scale information systems, such as databases, document management, and groupware that present significant obstacles to consistent cross-application use: dissimilar user interfaces, incompatible security schemes, and the undesirable property of serving only parts of the user community (islands of use) and accessing only some of the enterprise knowledge assets (islands of information).World Wide Web (WWW) architectures do not solve this problem directly. WWW software components are combinable in many clever ways but until recently there were no specific efforts to solve the enterprise computing problems of islands of use and information.The situation is changing now with nascent efforts to architect Web Portal systems with small software modules, for example with Java "portlets" or the Python-based Zope framework [15]. These are program-centric approaches to coalesce information sources and unify the query interface without inherent user modeling. This paper discusses in detail an alternative: a user-centered, conversational portal which extends the ALICE chatbot technology platform and links the user conveniently to information resources, such as Web Services, with specialized query routing. The approach offers scalability, extensibility, and coordination between end-users and developers. A university Intranet implementation, the Catacomb system, is presented and discussed to illustrate the advantages of the conversational Web portal approach.},
  issn     = {1581135939},
  keywords = {Alice, Conversational Portal, Portal Design, Query Routing, Computer Science},
  pages    = {84--87},
  refid    = {TN_acm584949},
  series   = {WIDM '02},
}

@Article{OShea2014,
  author   = {O'Shea, Karen},
  title    = {Natural language scripting within conversational agent design},
  journal  = {Applied Intelligence},
  year     = {2014},
  volume   = {40},
  number   = {1},
  pages    = {189--197},
  issn     = {0924669X},
  abstract = {  This paper presents a novel Semantic-Based Conversational Agent (SCA). Traditional conversational agents (CA) interpret scripts consisting of structural patterns of sentences, which take no consideration of semantic content. The script writer must therefore anticipate the many variations of input the user may respond with during dialogue. This is evidently a high maintenance task. Furthermore, different script writers possess differing levels of skill and as such this can prove to be an exasperating task. The proposed SCA interprets scripts consisting of natural language sentences by means of a semantic sentence similarity measure. User input is measured semantically against the natural language sentences of the current context in order to respond with an appropriate output string. Such scripting is effortless and alleviates the burden of the traditional pattern-scripted languages. Experiments have involved the use of script writers to demonstrate the use of the language. Results have highlighted the potential of the language and shown improvements on traditional pattern-scripted languages.[PUBLICATION ABSTRACT] Erratum DOI: 10.1007/s10489-013-0489-6},
  address  = {Boston},
  comment  = {  This paper presents a novel Semantic-Based Conversational Agent (SCA). Traditional conversational agents (CA) interpret scripts consisting of structural patterns of sentences, which take no consideration of semantic content. The script writer must therefore anticipate the many variations of input the user may respond with during dialogue. This is evidently a high maintenance task. Furthermore, different script writers possess differing levels of skill and as such this can prove to be an exasperating task. The proposed SCA interprets scripts consisting of natural language sentences by means of a semantic sentence similarity measure. User input is measured semantically against the natural language sentences of the current context in order to respond with an appropriate output string. Such scripting is effortless and alleviates the burden of the traditional pattern-scripted languages. Experiments have involved the use of script writers to demonstrate the use of the language. Results have highlighted the potential of the language and shown improvements on traditional pattern-scripted languages.[PUBLICATION ] Erratum DOI: 10.1007/s10489-013-0489-6},
  keywords = {Strings, Intelligence, Natural Language Processing, Sentences, Scripts, Tasks, Similarity, Maintenance, Semantics, Artificial Intelligence (General) (Ci);},
  refid    = {TN_proquest1476475822},
}

@Article{Shaked2017,
  author   = {Shaked, Nava A.},
  title    = {Avatars and virtual agents - relationship interfaces for the elderly},
  journal  = {Healthcare Technology Letters},
  year     = {2017},
  volume   = {4},
  number   = {3},
  pages    = {83--87},
  abstract = {In the Digital Era, the authors witness a change in the relationship between the patient and the care-giver or Health Maintenance Organization's providing the health services. Another fact is the use of various technologies to increase the effectiveness and quality of health services across all primary and secondary users. These technologies range from telemedicine systems, decision making tools, online and self-services applications and virtual agents
all providing information and assistance. The common thread between all these digital implementations, is they all require human machine interfaces. These interfaces must be interactive, user friendly and inviting, to create user involvement and cooperation incentives. The challenge is to design interfaces which will best fit the target users and enable smooth interaction especially, for the elderly users. Avatars and Virtual Agents are one of the interfaces used for both home care monitoring and companionship. They are also inherently multimodal in nature and allow an intimate relation between the elderly users and the Avatar. This study discusses the need and nature of these relationship models, the challenges of designing for the elderly. The study proposes key features for the design and evaluation in the area of assistive applications using Avatar and Virtual agents for the elderly users.},
  comment  = {In the Digital Era, the authors witness a change in the relationship between the patient and the care-giver or Health Maintenance Organization's providing the health services. Another fact is the use of various technologies to increase the effectiveness and quality of health services across all primary and secondary users. These technologies range from telemedicine systems, decision making tools, online and self-services applications and virtual agents; all providing information and assistance. The common thread between all these digital implementations, is they all require human machine interfaces. These interfaces must be interactive, user friendly and inviting, to create user involvement and cooperation incentives. The challenge is to design interfaces which will best fit the target users and enable smooth interaction especially, for the elderly users. Avatars and Virtual Agents are one of the interfaces used for both home care monitoring and companionship. They are also inherently multimodal in nature and allow an intimate relation between the elderly users and the Avatar. This study discusses the need and nature of these relationship models, the challenges of designing for the elderly. The study proposes key features for the design and evaluation in the area of assistive applications using Avatar and Virtual agents for the elderly users.},
  keywords = {Special Issue: Addressing Age-Related Conditions: Technologies For Early Detection, Geriatrics, Telemedicine, Man-Machine Systems, Avatars, Decision Making, Telemedicine Systems, Decision Making Tools, Human Machine Interfaces, Avatars, Virtual Agents, Home Care Monitoring, Elderly Users},
  refid    = {TN_pubmed_central5496465},
}

@Article{Savin-Baden2015,
  author   = {Savin-Baden, Maggi and Tombs, Gemma and Bhakta, Roy and Jandrić, Petar and Sinclair, Christine and Macleod, Hamish},
  title    = {Beyond robotic wastelands of time: Abandoned pedagogical agents and new pedalled pedagogies},
  journal  = {E-Learning and Digital Media},
  year     = {2015},
  volume   = {12},
  number   = {3-4},
  pages    = {295--314},
  issn     = {2042-7530},
  abstract = {Chatbots, known as pedagogical agents in educational settings, have a long history of use, beginning with Alan Turing's work. Since then online chatbots have become embedded into the fabric of technology. Yet understandings of these technologies are inchoate and often untheorised. Integration of chatbots into educational settings over the past five years suggests an increase in interest in the ways in which chatbots might be adopted and adapted for teaching and learning. This article draws on historical literature and theories that to date have largely been ignored in order to (re)contextualise two studies that used responsive evaluation to examine the use of pedagogical agents in education. Findings suggest that emotional interactions with pedagogical agents are intrinsic to a user's sense of trust, and that truthfulness, personalisation and emotional engagement are vital when using pedagogical agents to enhance online learning. Such findings need to be considered in the light of ways in which notions of learning are being redefined in the academy and the extent to which new literacies and new technologies are being pedalled as pedagogies in ways that undermine what higher education is, is for, and what learning means.},
  comment  = {Chatbots, known as pedagogical agents in educational settings, have a long history of use, beginning with Alan Turing's work. Since then online chatbots have become embedded into the fabric of technology. Yet understandings of these technologies are inchoate and often untheorised. Integration of chatbots into educational settings over the past five years suggests an increase in interest in the ways in which chatbots might be adopted and adapted for teaching and learning. This article draws on historical literature and theories that to date have largely been ignored in order to (re)contextualise two studies that used responsive evaluation to examine the use of pedagogical agents in education. Findings suggest that emotional interactions with pedagogical agents are intrinsic to a user's sense of trust, and that truthfulness, personalisation and emotional engagement are vital when using pedagogical agents to enhance online learning. Such findings need to be considered in the light of ways in which notions of learning are being redefined in the academy and the extent to which new literacies and new technologies are being pedalled as pedagogies in ways that undermine what higher education is, is for, and what learning means.},
  keywords = {Chatbots, Pedagogical Agents, Disclosure, Honesty, Mixed Methods, Evaluation},
  refid    = {TN_sagej10.1177_2042753015571835},
}

@Article{Hasler2013,
  author   = {Hasler, Béatrice S. and Tuchman, Peleg and Friedman, Doron},
  title    = {Virtual research assistants: Replacing human interviewers by automated avatars in virtual worlds},
  journal  = {Computers in Human Behavior},
  year     = {2013},
  issn     = {0747-5632},
  abstract = {Highlights► We provide support for the utility of automated avatars as virtual research assistants. ► Automated avatars are more efficient than human-controlled avatars in conducting survey interviews. ► Human-controlled avatars received more negative responses than an automated avatar. ► Virtual world experience predicted the willingness to disclose real-life information. ► Interviewer agency had no influence on real-life disclosure. We conducted an experiment to evaluate the use of embodied survey bots (i.e., software-controlled avatars) as a novel method for automated data collection in 3D virtual worlds. A bot and a human-controlled avatar carried out a survey interview within the virtual world, Second Life, asking participants about their religion. In addition to interviewer agency (bot vs. human), we tested participants’ virtual age, that is, the time passed since the person behind the avatar joined Second Life, as a predictor for response rate and quality. The human interviewer achieved a higher response rate than the bot. Participants with younger avatars were more willing to disclose information about their real life than those with older avatars. Surprisingly, the human interviewer received more negative responses than the bot. Affective reactions of older avatars were also more negative than those of younger avatars. The findings provide support for the utility of bots as virtual research assistants but raise ethical questions that need to be considered carefully.},
  comment  = {Highlights► We provide support for the utility of automated avatars as virtual research assistants. ► Automated avatars are more efficient than human-controlled avatars in conducting survey interviews. ► Human-controlled avatars received more negative responses than an automated avatar. ► Virtual world experience predicted the willingness to disclose real-life information. ► Interviewer agency had no influence on real-life disclosure. We conducted an experiment to evaluate the use of embodied survey bots (i.e., software-controlled avatars) as a novel method for automated data collection in 3D virtual worlds. A bot and a human-controlled avatar carried out a survey interview within the virtual world, Second Life, asking participants about their religion. In addition to interviewer agency (bot vs. human), we tested participants’ virtual age, that is, the time passed since the person behind the avatar joined Second Life, as a predictor for response rate and quality. The human interviewer achieved a higher response rate than the bot. Participants with younger avatars were more willing to disclose information about their real life than those with older avatars. Surprisingly, the human interviewer received more negative responses than the bot. Affective reactions of older avatars were also more negative than those of younger avatars. The findings provide support for the utility of bots as virtual research assistants but raise ethical questions that need to be considered carefully.},
  keywords = {Social Virtual Worlds, Automated Data Collection, Survey Interviewing, Bots, Avatars, Media Equation},
  refid    = {TN_sciversesciencedirect_elsevierS0747-5632(13)00007-1},
}

@Other{Nair-Ghaswalla2017,
  author   = {Nair-Ghaswalla, Amrita},
  title    = {How the bots are helping brands},
  year     = {2017},
  abstract = {Suhale Kapoor, Executive Vice-President and Co-founder of Absolutdata, a research and analytics firm, says brands these days are rapidly embracing the capabilities of AI to change the dynamics of marketing, and to provide a personalised user experience. “Since AI has become a part of our lives, marketers are realising that AI can help them to better understand, connect with, and create superior purchase experiences for consumers,” he adds. Since Google turned to AI and machine learning to help it identify objectionable content, several Indian e-commerce ventures are realising its true potential. Precise findingsHarsh Shah, Co-Founder of fashion e-commerce portal Fynd, says since customers tend to shop a lot online, “more than ever before, this gives e-commerce companies a lot of data points starting from which products customers view, which products they like, what they add to the cart and finally purchase. [...]these brands will soon have to learn how to...},
  address  = {Chennai},
  comment  = {Suhale Kapoor, Executive Vice-President and Co-founder of Absolutdata, a research and analytics firm, says brands these days are rapidly embracing the capabilities of AI to change the dynamics of marketing, and to provide a personalised user experience. “Since AI has become a part of our lives, marketers are realising that AI can help them to better understand, connect with, and create superior purchase experiences for consumers,” he adds. Since Google turned to AI and machine learning to help it identify objectionable content, several Indian e-commerce ventures are realising its true potential. Precise findingsHarsh Shah, Co-Founder of fashion e-commerce portal Fynd, says since customers tend to shop a lot online, “more than ever before, this gives e-commerce companies a lot of data points starting from which products customers view, which products they like, what they add to the cart and finally purchase. [...]these brands will soon have to learn how to...},
  journal  = {Businessline},
  keywords = {United States-Us, Social Networks, Marketing, User Experience, Artificial Intelligence, Consumers, Electronic Commerce, Verizon Communications Inc, At&T Inc, Microsoft Corp, Google Inc, Youtube Inc, Johnson & Johnson},
  refid    = {TN_proquest1918708786},
}

@Article{Tatai2003,
  author  = {Tatai, G. and Csordas, A. and Kiss, A. and Szalo, A. and Laufer, L.},
  title   = {Happy chatbot, happy user},
  journal = {Intelligent Virtual Agents},
  year    = {2003},
  volume  = {2792},
  pages   = {5--12},
  issn    = {0302-9743},
  refid   = {TN_wos000187008600002},
}

@Other{Perez-Marin2011,
  author    = {Perez-Marin, Diana and Pascual-Nieto, Ismael and Pascual-Nieto, Ismael and Perez-Marin, Diana},
  title     = {Conversational agents and natural language interaction : techniques and effective practices},
  year      = {2011},
  issn      = {1-283-15310-6},
  journal   = {CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION},
  keywords  = {Natural language processing (Computer science) -- Data processing, Computer-assisted instruction -- Data processing, Discourse analysis, Speech therapy, Intelligent agents (Computer software), Engineering & Applied Sciences, Computer Science},
  publisher = {Information Science Reference},
  refid     = {BIBSYS_ILS71530697930002201},
}

@Article{Meyer2016,
  author   = {Meyer, Joachim and Miller, Chris and Hancock, Peter and de Visser, Ewart J. and Dorneich, Michael},
  title    = {Politeness in Machine-Human and Human-Human Interaction},
  journal  = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  year     = {2016},
  volume   = {60},
  number   = {1},
  pages    = {279--283},
  doi      = {10.1177/1541931213601064},
  url      = {http://journals.sagepub.com/doi/abs/10.1177/1541931213601064},
  abstract = {Computers communicate with humans in ways that increasingly resemble interactions between humans. Nuances in expression and responses to human behavior become more sophisticated, and they approach those of human-human interaction. The question arises whether we want systems eventually to behave like humans, or whether systems should, even when much more developed, still adhere to rules that are different from the rules governing interpersonal communication. The panel addresses this issue from various perspectives, eventually aiming to gain some insights into the question of the direction to which the development of machine-human communication and the etiquette implemented in the systems should move.},
}

@Article{Lee2004,
  author   = {Lee, John D. and See, Katrina A.},
  title    = {Trust in Automation: Designing for Appropriate Reliance},
  journal  = {Human Factors},
  year     = {2004},
  volume   = {46},
  number   = {1},
  pages    = {50--80},
  doi      = {10.1518/hfes.46.1.50_30392},
  url      = {http://journals.sagepub.com/doi/abs/10.1518/hfes.46.1.50_30392},
  abstract = {Automation is often problematic because people fail to rely upon it appropriately. Because people respond to technology socially, trust influences reliance on automation. In particular, trust guides reliance when complexity and unanticipated situations make a complete understanding of the automation impractical. This review considers trust from the organizational, sociological, interpersonal, psychological, and neurological perspectives. It considers how the context, automation characteristics, and cognitive processes affect the appropriateness of trust. The context in which the automation is used influences automation performance and provides a goal-oriented perspective to assess automation characteristics along a dimension of attributional abstraction. These characteristics can influence trust through analytic, analogical, and affective processes. The challenges of extrapolating the concept of trust in people to trust in automation are discussed. A conceptual model integrates research regarding trust in automation and describes the dynamics of trust, the role of context, and the influence of display characteristics. Actual or potential applications of this research include improved designs of systems that require people to manage imperfect automation.},
}

@Article{Waytz2010,
  author   = {Waytz, Adam and Cacioppo, John and Epley, Nicholas},
  title    = {Who Sees Human?:The Stability and Importance of Individual Differences in Anthropomorphism},
  journal  = {Perspectives on Psychological Science},
  year     = {2010},
  volume   = {5},
  number   = {3},
  pages    = {219--232},
  doi      = {10.1177/1745691610369336},
  url      = {http://journals.sagepub.com/doi/abs/10.1177/1745691610369336},
  abstract = {Anthropomorphism is a far-reaching phenomenon that incorporates ideas from social psychology, cognitive psychology, developmental psychology, and the neurosciences. Although commonly considered to be a relatively universal phenomenon with only limited importance in modern industrialized societies—more cute than critical—our research suggests precisely the opposite. In particular, we provide a measure of stable individual differences in anthropomorphism that predicts three important consequences for everyday life. This research demonstrates that individual differences in anthropomorphism predict the degree of moral care and concern afforded to an agent, the amount of responsibility and trust placed on an agent, and the extent to which an agent serves as a source of social influence on the self. These consequences have implications for disciplines outside of psychology including human–computer interaction, business (marketing and finance), and law. Concluding discussion addresses how understanding anthropomorphism not only informs the burgeoning study of nonpersons, but how it informs classic issues underlying person perception as well.},
  keywords = {anthropomorphism,social cognition,individual differences},
}

@Article{Kim0,
  author   = {Kim, Sara and Zhang, Ke and Park, Daeun},
  title    = {Don’t Want to Look Dumb? The Role of Theories of Intelligence and Humanlike Features in Online Help Seeking},
  journal  = {Psychological Science},
  year     = {0},
  volume   = {0},
  number   = {0},
  pages    = {0956797617730595},
  doi      = {10.1177/0956797617730595},
  url      = {http://journals.sagepub.com/doi/abs/10.1177/0956797617730595},
  abstract = {Numerous studies have shown that individuals’ help-seeking behavior increases when a computerized helper is endowed with humanlike features in nonachievement contexts. In contrast, the current research suggests that anthropomorphic helpers are not universally conducive to help-seeking behavior in contexts of achievement, particularly among individuals who construe help seeking as a display of incompetence (i.e., entity theorists). Study 1 demonstrated that when entity theorists received help from an anthropomorphized (vs. a nonanthropomorphized) helper, they were more concerned about negative judgments from other people, whereas incremental theorists were not affected by anthropomorphic features. Study 2 showed that when help was provided by an anthropomorphized (vs. a nonanthropomorphized) helper, entity theorists were less likely to seek help, even at the cost of lower performance. In contrast, incremental theorists’ help-seeking behavior and task performance were not affected by anthropomorphism. This research deepens the current understanding of the role of anthropomorphic computerized helpers in online learning contexts.},
  keywords = {theories of intelligence,help seeking,anthropomorphism,task performance,online learning,open data,open materials},
}

@Article{Duijst2017,
  author = {Duijst, Daniëlle},
  title  = {Can we Improve the User Experience of Chatbots with Personalisation?},
  year   = {2017},
}

@Article{Niculescu2009,
  author    = {Niculescu, A. I. and Van Der Sluis, Frans and Nijholt, Anton},
  title     = {Feminity, masculinity and androgyny: how humans perceive the gender of anthropomorphic agents},
  year      = {2009},
  publisher = {Springer Verlag},
}

@Article{Zimmerman2005,
  author    = {Zimmerman, John and Ayoob, Ellen and Forlizzi, Jodi and McQuaid, Mick},
  title     = {Putting a face on embodied interface agents},
  year      = {2005},
  publisher = {Eindhoven Technical University Press},
}

@Misc{Stern2003,
  author    = {Stern, Andrew},
  title     = {Creating Emotional Relationships With Virtual Characters; from: Emotions in Humans and Artifacts, eds. R. Trappl, P. Petta, and S. Payr},
  year      = {2003},
  publisher = {MIT Press},
}

@Book{Cohen2004,
  author    = {Cohen, Michael H. and Cohen, Michael Harris and Giangola, James P. and Balogh, Jennifer},
  title     = {Voice user interface design},
  year      = {2004},
  publisher = {Addison-Wesley Professional},
}

@InProceedings{Mauldin1994,
  author    = {Mauldin, Michael L.},
  title     = {Chatterbots, tinymuds, and the turing test: Entering the loebner prize competition},
  booktitle = {AAAI},
  year      = {1994},
  volume    = {94},
  pages     = {16--21},
}

@Article{Turing1950,
  author    = {Turing, Alan M.},
  title     = {Computing machinery and intelligence},
  journal   = {Mind},
  year      = {1950},
  volume    = {59},
  number    = {236},
  pages     = {433--460},
  publisher = {JSTOR},
}

@InProceedings{Beun2003,
  author    = {Beun, Robbert-Jan and De Vos, Eveliene and Witteman, Cilia},
  title     = {Embodied conversational agents: effects on memory performance and anthropomorphisation},
  booktitle = {IVA},
  year      = {2003},
  publisher = {Springer},
  pages     = {315--319},
}

@InProceedings{Feil-Seifer2008,
  author    = {Feil-Seifer, David and Mataric, Maja},
  title     = {Robot-assisted therapy for children with autism spectrum disorders},
  booktitle = {Proceedings of the 7th international conference on Interaction design and children},
  year      = {2008},
  publisher = {ACM},
  pages     = {49--52},
}

@Article{Epley2007,
  author    = {Epley, Nicholas and Waytz, Adam and Cacioppo, John T.},
  title     = {On seeing human: a three-factor theory of anthropomorphism.},
  journal   = {Psychological review},
  year      = {2007},
  volume    = {114},
  number    = {4},
  pages     = {864},
  publisher = {American Psychological Association},
}

@Article{Mori1970,
  author  = {Mori, Masahiro},
  title   = {The uncanny valley},
  journal = {Energy},
  year    = {1970},
  volume  = {7},
  number  = {4},
  pages   = {33--35},
}

@Article{Nass2000,
  author    = {Nass, Clifford and Moon, Youngme},
  title     = {Machines and mindlessness: Social responses to computers},
  journal   = {Journal of social issues},
  year      = {2000},
  volume    = {56},
  number    = {1},
  pages     = {81--103},
  publisher = {Wiley Online Library},
}

@Article{Lucas2014,
  author    = {Lucas, Gale M. and Gratch, Jonathan and King, Aisha and Morency, Louis-Philippe},
  title     = {It’s only a computer: Virtual humans increase willingness to disclose},
  journal   = {Computers in Human Behavior},
  year      = {2014},
  volume    = {37},
  pages     = {94--100},
  publisher = {Elsevier},
}

@InProceedings{Prada2003,
  author    = {Prada, Rui and Vala, Marco and Paiva, Ana and Hook, Kristina and Bullock, Adrian},
  title     = {FantasyA–The Duel of Emotions},
  booktitle = {International Workshop on Intelligent Virtual Agents},
  year      = {2003},
  publisher = {Springer},
  pages     = {62--66},
}

@Article{Dautenhahn2002,
  author    = {Dautenhahn, Kerstin and Ogden, Bernard and Quick, Tom},
  title     = {From embodied to socially embedded agents–implications for interaction-aware robots},
  journal   = {Cognitive Systems Research},
  year      = {2002},
  volume    = {3},
  number    = {3},
  pages     = {397--428},
  publisher = {Elsevier},
}

@InProceedings{Inbar2015,
  author    = {Inbar, Ohad and Meyer, Joachim},
  title     = {Manners matter: Trust in robotic peacekeepers},
  booktitle = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  year      = {2015},
  volume    = {59},
  number    = {1},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA},
  pages     = {185--189},
}

@Book{Nof2009,
  author    = {Nof, Shimon Y.},
  title     = {Springer handbook of automation},
  year      = {2009},
  publisher = {Springer Science \& Business Media},
}

@Article{McCrae1992,
  author    = {McCrae, Robert R. and John, Oliver P.},
  title     = {An introduction to the five‐factor model and its applications},
  journal   = {Journal of personality},
  year      = {1992},
  volume    = {60},
  number    = {2},
  pages     = {175--215},
  publisher = {Wiley Online Library},
}

@InProceedings{Dirk2003,
  author    = {Dirk, Heylen},
  title     = {Talking Head Says Cheese},
  booktitle = {Humor as an impetus for Embodied Conversational Agent Research. CHI-2003 WorkShop: Humor Modeling In the Interface},
  year      = {2003},
}

@InProceedings{Dybala2009,
  author    = {Dybala, Pawel and Ptaszynski, Michal and Rzepka, Rafal and Araki, Kenji},
  title     = {Humoroids: conversational agents that induce positive emotions with humor},
  booktitle = {Proceedings of The 8th International Conference on Autonomous Agents and Multiagent Systems-Volume 2},
  year      = {2009},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  pages     = {1171--1172},
}

@Article{Mencia2012,
  author    = {Mencía, Beatriz López and Pardo, David Díaz and Trapote, Alvaro Hernández and Gómez, Luis A. Hernández},
  title     = {Embodied Conversational Agents in Interactive Applications for Children with Special Educational Needs},
  journal   = {Technologies for Inclusive Education: Beyond Traditional Integration Approaches: Beyond Traditional Integration Approaches},
  year      = {2012},
  pages     = {59},
  publisher = {IGI Global},
}

@Article{Jung1923,
  author    = {Jung, Carl Gustav},
  title     = {Psychological types: or the psychology of individuation.},
  year      = {1923},
  publisher = {Harcourt, Brace},
}

@Book{Myers2010,
  author    = {Myers, Isabel and Myers, Peter},
  title     = {Gifts differing: Understanding personality type},
  year      = {2010},
  publisher = {Nicholas Brealey Publishing},
}

@Article{Delin2005,
  author  = {Delin, Judy},
  title   = {Brand Tone of Voice: a linguistic analysis of brand positions.},
  journal = {Journal of Applied Linguistics},
  year    = {2005},
  volume  = {2},
  number  = {1},
}

@InProceedings{Tatai2003a,
  author    = {Tatai, Gábor and Csordás, Annamária and Kiss, Árpád and Laufer, László and Szaló, Attila},
  title     = {The chatbot who loved me},
  booktitle = {proceedings of the ECA workshop of AAMAS},
  year      = {2003},
}

@InCollection{Augello2011,
  author    = {Augello, Agnese and Gambino, Orazio and Cannella, Vincenzo and Pirrone, Roberto and Gaglio, Salvatore and Pilato, Giovanni},
  title     = {An Emotional Talking Head for a Humoristic Chatbot},
  booktitle = {Applications of Digital Signal Processing},
  year      = {2011},
  publisher = {InTech},
}

@Article{Beran,
  author    = {Beran, Ondřej},
  title     = {An Attitude Towards an Artificial Soul? Responses to the “Nazi Chatbot”},
  journal   = {Philosophical Investigations},
  publisher = {Wiley Online Library},
}

@PhdThesis{Woudenberg2014,
  author = {Woudenberg, Aswin van},
  title  = {A Chatbot Dialogue Manager-Chatbots and Dialogue Systems: A Hybrid Approach},
  year   = {2014},
  school = {Open Universiteit Nederland},
}

@InCollection{McTear2016a,
  author    = {McTear, Michael and Callejas, Zoraida and Griol, David},
  title     = {Conversational Interfaces: Past and Present},
  booktitle = {The Conversational Interface},
  year      = {2016},
  publisher = {Springer},
  pages     = {51--72},
}

@Article{Waytz2014,
  author   = {Waytz, Adam and Heafner, Joy and Epley, Nicholas},
  title    = {The mind in the machine: Anthropomorphism increases trust in an autonomous vehicle},
  journal  = {Journal of Experimental Social Psychology},
  year     = {2014},
  volume   = {52},
  number   = {Supplement C},
  month    = may,
  pages    = {113--117},
  issn     = {0022-1031},
  url      = {http://www.sciencedirect.com/science/article/pii/S0022103114000067},
  keywords = {Anthropomorphism, Mind perception, Trust, Moral responsibility, Human-computer interaction, Dehumanization},
}

@Article{Gosling2003,
  author  = {Gosling, Samuel D. and Rentfrow, Peter J. and Swann, William B.},
  title   = {A very brief measure of the Big-Five personality domains},
  journal = {Journal of Research in Personality},
  year    = {2003},
  volume  = {37},
  number  = {6},
  month   = dec,
  pages   = {504--528},
  issn    = {0092-6566},
  url     = {http://www.sciencedirect.com/science/article/pii/S0092656603000461},
}

@Article{Kim2012,
  author   = {Kim, Youjeong and Sundar, S. Shyam},
  title    = {Anthropomorphism of computers: Is it mindful or mindless?},
  journal  = {Computers in Human Behavior},
  year     = {2012},
  volume   = {28},
  number   = {1},
  month    = jan,
  pages    = {241--250},
  issn     = {0747-5632},
  url      = {http://www.sciencedirect.com/science/article/pii/S0747563211001993},
  keywords = {Anthropomorphism, Interactivity, Human-like agent, Social presence, Information credibility},
}

@Article{Shank2013,
  author   = {Shank, Daniel B.},
  title    = {Are computers good or bad for business? How mediated customer-computer interaction alters emotions, impressions, and patronage toward organizations},
  journal  = {Computers in Human Behavior},
  year     = {2013},
  volume   = {29},
  number   = {3},
  month    = may,
  pages    = {715--725},
  issn     = {0747-5632},
  url      = {http://www.sciencedirect.com/science/article/pii/S0747563212003111},
  keywords = {Computers are social actors, Organizations, Human-computer interaction, Customers, Computer mediation, Emotion},
}

@Article{Culley2013,
  author   = {Culley, Kimberly E. and Madhavan, Poornima},
  title    = {A note of caution regarding anthropomorphism in HCI agents},
  journal  = {Computers in Human Behavior},
  year     = {2013},
  volume   = {29},
  number   = {3},
  month    = may,
  pages    = {577--579},
  issn     = {0747-5632},
  url      = {http://www.sciencedirect.com/science/article/pii/S0747563212003287},
  keywords = {HCI, Universal usability, Anthropomorphism, Affect as information, Trust, Agent},
}

@Article{Corti2016,
  author   = {Corti, Kevin and Gillespie, Alex},
  title    = {Co-constructing intersubjectivity with artificial conversational agents: People are more likely to initiate repairs of misunderstandings with agents represented as human},
  journal  = {Computers in Human Behavior},
  year     = {2016},
  volume   = {58},
  number   = {Supplement C},
  month    = may,
  pages    = {431--442},
  issn     = {0747-5632},
  url      = {http://www.sciencedirect.com/science/article/pii/S0747563215303101},
  keywords = {Common ground, Conversational repair, Echoborg, Human-agent interaction, Intersubjectivity, Psychological benchmarks},
}

@Book{Perez-Marin2011a,
  author    = {Perez-Marin, Diana and Pascual-Nieto, Ismael},
  title     = {Conversational Agents and Natural Language Interaction : Techniques and Effective Practices},
  year      = {2011},
  publisher = {Hershey, US: IGI Global},
  address   = {Hershey},
  comment   = {Conversational Agents and Natural Language Interaction: Techniques and Effective Practices is a reference guide for researchers entering the promising field of conversational agents. It provides an introduction to fundamental concepts in the field, collects experiences of researchers working on conversational agents, and reviews techniques for the design and application of conversational agents. The book discusses the successes of and challenges faced by researchers, designers, and programmers who want to use conversational agents for e-commerce, help desks, website navigation, personalized service, and training or education applications.},
  issn      = {9781609606183},
  keywords  = {Medical, Audiology & Speech Pathology},
  refid     = {TN_ebrary_pqebrary10480601},
}

@Article{Barcelos2017,
  author   = {Barcelos, Renato Hübner and Dantas, Danilo Correa and Sénécal, Sylvain},
  title    = {Watch Your Tone: How a Brand's Tone of Voice on Social Media Influences Consumer Responses},
  journal  = {Journal of Interactive Marketing},
  year     = {2017},
  issn     = {1094-9968},
  abstract = {Social media platforms enable firms to communicate directly and often publicly with individual consumers. In this research, comprising four online studies, the authors investigate how the tone of voice used by firms (human vs. corporate) influences purchase intentions on social media. Findings suggest that a human tone of voice is not always the firm's best option. Study 1a (N=174) shows that using a human voice, instead of the more traditional corporate voice, can increase a consumer's hedonic value on social media and also purchase intentions. However, that influence of a human voice on purchase intentions is stronger when the consumer is looking at a brand page with a hedonic goal in mind (versus a utilitarian one). Study 1b (N=342) shows that the presence of several negative comments about a brand on social media acts as a boundary condition, nullifying the influence of a human voice on purchase intentions. Studies 2a (N=154) and 2b (N=202) show in different settings that using a human voice can even reduce purchase intentions in contexts of high situational involvement, due to perceptions of risk associated with humanness. The results contribute to the literature surrounding the effects of conversational human voice, while also providing managers with a set of guidelines to help inform and identify which tone of voice is best adapted to each communications scenario. •The tone of voice used by firms influences purchase intentions on social media.•Four online studies investigate the influence of human vs. corporate tone of voice.•A human tone of voice increases purchase intentions in hedonic, low-risk contexts.•The influence of the tone of voice is weakened in utilitarian, low-risk contexts.•A human tone of voice decreases purchase intentions in high-risk contexts.},
  comment  = {Social media platforms enable firms to communicate directly and often publicly with individual consumers. In this research, comprising four online studies, the authors investigate how the tone of voice used by firms (human vs. corporate) influences purchase intentions on social media. Findings suggest that a human tone of voice is not always the firm's best option. Study 1a (N=174) shows that using a human voice, instead of the more traditional corporate voice, can increase a consumer's hedonic value on social media and also purchase intentions. However, that influence of a human voice on purchase intentions is stronger when the consumer is looking at a brand page with a hedonic goal in mind (versus a utilitarian one). Study 1b (N=342) shows that the presence of several negative comments about a brand on social media acts as a boundary condition, nullifying the influence of a human voice on purchase intentions. Studies 2a (N=154) and 2b (N=202) show in different settings that using a human voice can even reduce purchase intentions in contexts of high situational involvement, due to perceptions of risk associated with humanness. The results contribute to the literature surrounding the effects of conversational human voice, while also providing managers with a set of guidelines to help inform and identify which tone of voice is best adapted to each communications scenario. •The tone of voice used by firms influences purchase intentions on social media.•Four online studies investigate the influence of human vs. corporate tone of voice.•A human tone of voice increases purchase intentions in hedonic, low-risk contexts.•The influence of the tone of voice is weakened in utilitarian, low-risk contexts.•A human tone of voice decreases purchase intentions in high-risk contexts.},
  keywords = {Human Voice, Social Presence, Social Media, Online Branding, Digital Marketing},
  refid    = {TN_sciversesciencedirect_elsevierS1094-9968(17)30057-9},
}

@Other{Lester1997,
  author   = {Lester, James and Converse, Sharolyn and Kahler, Susan and Barlow, S. and Stone, Brian and Bhogal, Ravinder},
  title    = {The persona effect: affective impact of animated pedagogical agents},
  year     = {1997},
  comment  = {<b>Related Persons: </b>Pemberton, Steven},
  issn     = {0897918029},
  keywords = {Agents, Children, Educational Applications, Empirical Studies, Intelligent Systems},
  pages    = {359--366},
  refid    = {TN_acm258797},
  series   = {CHI '97},
}

@Article{Lee2010,
  author   = {Lee, Eun-Ju},
  title    = {The more humanlike, the better? How speech type and users’ cognitive style affect social responses to computers},
  journal  = {Computers in Human Behavior},
  year     = {2010},
  volume   = {26},
  number   = {4},
  pages    = {665--672},
  issn     = {0747-5632},
  abstract = {The present experiment investigated if anthropomorphic interfaces facilitate people’s tendency to project social expectations onto computers and how such effects might vary depending on users’ cognitive style. In a 2 (synthetic vs. recorded speech) × 2 (flattering vs. generic feedback) × 2 (low vs. high rationality) × 2 (low vs. high experientiality) experiment, participants played a trivia game with a computer. Use of recorded speech did not amplify the previously documented flattery effects ( Fogg & Nass, 1997), challenging the notion that anthropomorphism will promote social responses to computers. Participants evaluated the human-voiced computer more positively and conformed more to its suggestions than the one using synthetic speech, but such effects were found only among less analytical or more intuition-driven individuals, suggesting dispositional differences in people’s susceptibility to anthropomorphic cues embedded in the interface.},
  comment  = {The present experiment investigated if anthropomorphic interfaces facilitate people’s tendency to project social expectations onto computers and how such effects might vary depending on users’ cognitive style. In a 2 (synthetic vs. recorded speech) × 2 (flattering vs. generic feedback) × 2 (low vs. high rationality) × 2 (low vs. high experientiality) experiment, participants played a trivia game with a computer. Use of recorded speech did not amplify the previously documented flattery effects ( Fogg & Nass, 1997), challenging the notion that anthropomorphism will promote social responses to computers. Participants evaluated the human-voiced computer more positively and conformed more to its suggestions than the one using synthetic speech, but such effects were found only among less analytical or more intuition-driven individuals, suggesting dispositional differences in people’s susceptibility to anthropomorphic cues embedded in the interface.},
  keywords = {Anthropomorphism, Computers Are Social Actors (Casa), Experientiality, Rationality},
  refid    = {TN_sciversesciencedirect_elsevierS0747-5632(10)00005-1},
}

@Article{Schroeder2016,
  author   = {Schroeder, Juliana and Epley, Nicholas},
  title    = {Mistaking Minds and Machines: How Speech Affects Dehumanization and Anthropomorphism},
  journal  = {Journal of Experimental Psychology: General},
  year     = {2016},
  issn     = {0096-3445},
  abstract = {Treating a human mind like a machine is an essential component of dehumanization, whereas attributing a humanlike mind to a machine is an essential component of anthropomorphism. Here we tested how a cue closely connected to a person’s actual mental experience--a humanlike voice--affects the likelihood of mistaking a person for a machine, or a machine for a person. We predicted that paralinguistic cues in speech are particularly likely to convey the presence of a humanlike mind, such that removing voice from communication (leaving only text) would increase the likelihood of mistaking the text’s creator for a machine. Conversely, adding voice to a computer-generated script (resulting in speech) would increase the likelihood of mistaking the text’s creator for a human. Four experiments confirmed these hypotheses, demonstrating that people are more likely to infer a human (vs. computer) creator when they hear a voice expressing thoughts than when they read the same thoughts in text. Adding human visual cues to text (i.e., seeing a person perform a script in a subtitled video clip), did not increase the likelihood of inferring a human creator compared with only reading text, suggesting that defining features of personhood may be conveyed more clearly in speech (Experiments 1 and 2). Removing the naturalistic paralinguistic cues that convey humanlike capacity for thinking and feeling, such as varied pace and intonation, eliminates the humanizing effect of speech (Experiment 4). We discuss implications for dehumanizing others through text-based media, and for anthropomorphizing machines through speech-based media.},
  comment  = {Treating a human mind like a machine is an essential component of dehumanization, whereas attributing a humanlike mind to a machine is an essential component of anthropomorphism. Here we tested how a cue closely connected to a person’s actual mental experience--a humanlike voice--affects the likelihood of mistaking a person for a machine, or a machine for a person. We predicted that paralinguistic cues in speech are particularly likely to convey the presence of a humanlike mind, such that removing voice from communication (leaving only text) would increase the likelihood of mistaking the text’s creator for a machine. Conversely, adding voice to a computer-generated script (resulting in speech) would increase the likelihood of mistaking the text’s creator for a human. Four experiments confirmed these hypotheses, demonstrating that people are more likely to infer a human (vs. computer) creator when they hear a voice expressing thoughts than when they read the same thoughts in text. Adding human visual cues to text (i.e., seeing a person perform a script in a subtitled video clip), did not increase the likelihood of inferring a human creator compared with only reading text, suggesting that defining features of personhood may be conveyed more clearly in speech (Experiments 1 and 2). Removing the naturalistic paralinguistic cues that convey humanlike capacity for thinking and feeling, such as varied pace and intonation, eliminates the humanizing effect of speech (Experiment 4). We discuss implications for dehumanizing others through text-based media, and for anthropomorphizing machines through speech-based media.},
  keywords = {Communication, Voice, Mind Perception, Dehumanization, Anthropomorphism},
  refid    = {TN_apa_articles10.1037/xge0000214},
}

@Other{Lu2010,
  author   = {Lu, Caimei and Park, Jung-Ran and Hu, Xiaohua and Song, Il-Yeol},
  title    = {Metadata Effectiveness: A Comparison between User-Created Social Tags and Author-Provided Metadata},
  year     = {2010},
  abstract = {This paper aims to investigate the additional information value provided by user-created social tags and author-provided metadata as well as their effectiveness in facilitating web clustering and discovery. We collected a data set of web pages that includes both social tags from the del.icio.us website and author-provided metadata crawled from the internet. Based on this data set, we first checked the overlap of user-created tags and author-provided metadata with the title and content of the annotated web pages. Then, we experimented on two clustering methods based on tags and author-provided metadata. The results show that both tags and author-provided metadata add valuable information to existing page content and that social tags are more effective than author-created metadata for enhancing web clustering performance either as an independent information source or as links connecting topically related pages.},
  comment  = {This paper aims to investigate the additional information value provided by user-created social tags and author-provided metadata as well as their effectiveness in facilitating web clustering and discovery. We collected a data set of web pages that includes both social tags from the del.icio.us website and author-provided metadata crawled from the internet. Based on this data set, we first checked the overlap of user-created tags and author-provided metadata with the title and content of the annotated web pages. Then, we experimented on two clustering methods based on tags and author-provided metadata. The results show that both tags and author-provided metadata add valuable information to existing page content and that social tags are more effective than author-created metadata for enhancing web clustering performance either as an independent information source or as links connecting topically related pages.},
  issn     = {978-1-4244-5509-6},
  journal  = {System Sciences (HICSS), 2010 43rd Hawaii International Conference on},
  pages    = {1--10},
  refid    = {TN_ieee10.1109/HICSS.2010.273},
}

@Article{Golder2005,
  author   = {Golder, Scott and Huberman, Bernardo A.},
  title    = {The Structure of Collaborative Tagging Systems},
  year     = {2005},
  abstract = {Collaborative tagging describes the process by which many users add metadata in the form of keywords to shared content. Recently, collaborative tagging has grown in popularity on the web, on sites that allow users to tag bookmarks, photographs and other content. In this paper we analyze the structure of collaborative tagging systems as well as their dynamical aspects. Specifically, we discovered regularities in user activity, tag frequencies, kinds of tags used, bursts of popularity in bookmarking and a remarkable stability in the relative proportions of tags within a given url. We also present a dynamical model of collaborative tagging that predicts these stable patterns and relates them to imitation and shared knowledge.},
  comment  = {Collaborative tagging describes the process by which many users add metadata in the form of keywords to shared content. Recently, collaborative tagging has grown in popularity on the web, on sites that allow users to tag bookmarks, photographs and other content. In this paper we analyze the structure of collaborative tagging systems as well as their dynamical aspects. Specifically, we discovered regularities in user activity, tag frequencies, kinds of tags used, bursts of popularity in bookmarking and a remarkable stability in the relative proportions of tags within a given url. We also present a dynamical model of collaborative tagging that predicts these stable patterns and relates them to imitation and shared knowledge.},
  keywords = {Computer Science - Digital Libraries, Computer Science - Computers And Society},
  refid    = {TN_arxivcs/0508082},
}

@Article{Furnas1987,
  author   = {Furnas, G. and Landauer, T. and Gomez, L. and Dumais, S.},
  title    = {The vocabulary problem in human-system communication},
  journal  = {Communications of the ACM},
  year     = {1987},
  volume   = {30},
  number   = {11},
  pages    = {964--971},
  issn     = {0001-0782},
  abstract = {<p><p>In almost all computer applications, users must enter correct words for the desired objects or actions. For success without extensive training, or in first-tries for new targets, the system must recognize terms that will be chosen spontaneously. We studied spontaneous word choice for objects in five application-related domains, and found the variability to be surprisingly large. In every case two people favored the same term with probability <0.20. Simulations show how this fundamental property of language limits the success of various design methodologies for vocabulary-driven interaction. For example, the popular approach in which access is via one designer's favorite single word will result in 80-90 percent failure rates in many common situations. An optimal strategy, unlimited aliasing, is derived and shown to be capable of several-fold improvements.</p></p>},
  comment  = {In almost all computer applications, users must enter correct words for the desired objects or actions. For success without extensive training, or in first-tries for new targets, the system must recognize terms that will be chosen spontaneously. We studied spontaneous word choice for objects in five application-related domains, and found the variability to be surprisingly large. In every case two people favored the same term with probability &lt;0.20. Simulations show how this fundamental property of language limits the success of various design methodologies for vocabulary-driven interaction. For example, the popular approach in which access is via one designer's favorite single word will result in 80-90 percent failure rates in many common situations. An optimal strategy, unlimited aliasing, is derived and shown to be capable of several-fold improvements.},
  keywords = {Engineering, Computer Science, Mathematics},
  refid    = {TN_acm32212},
}

@Article{Holtgraves2007,
  author   = {Holtgraves, T. M. and Ross, S. J. and Weywadt, C. R. and Han, T. L.},
  title    = {Perceiving artificial social agents},
  journal  = {Computers in Human Behavior},
  year     = {2007},
  volume   = {23},
  number   = {5},
  pages    = {2163--2174},
  issn     = {0747-5632},
  abstract = {Three experiments were conducted to examine perceptions of a natural language computer interface (conversation bot). Participants in each study chatted with a conversation bot and then indicated their perceptions of the bot on various dimensions. Although participants were informed that they were interacting with a computer program, participants clearly viewed the program as having human-like qualities. Participants agreed substantially in their perceptions of the bot’s personality on the traits from the five-factor model (Experiment 1). In addition, factors that influence perceptions of human personalities (e.g., whether one uses another’s first name and response latency) also affected perceptions of a bot’s personality (Experiments 2 and 3). Similar to interactions with humans, the bot’s perceived neuroticism was inversely related to how long individuals chatted with it.},
  comment  = {Three experiments were conducted to examine perceptions of a natural language computer interface (conversation bot). Participants in each study chatted with a conversation bot and then indicated their perceptions of the bot on various dimensions. Although participants were informed that they were interacting with a computer program, participants clearly viewed the program as having human-like qualities. Participants agreed substantially in their perceptions of the bot’s personality on the traits from the five-factor model (Experiment 1). In addition, factors that influence perceptions of human personalities (e.g., whether one uses another’s first name and response latency) also affected perceptions of a bot’s personality (Experiments 2 and 3). Similar to interactions with humans, the bot’s perceived neuroticism was inversely related to how long individuals chatted with it.},
  keywords = {Personality, Mathematical Models, Natural Language (Computers), Computer Simulation, C (Programming Language), Computer Programs, User Interfaces (Ci), Article;},
  refid    = {TN_sciversesciencedirect_elsevierS0747-5632(06)00039-2},
}

@Other{Norman2007,
  author    = {Norman, Donald A.},
  title     = {Emotional design : why we love (or hate) everyday things},
  year      = {2007},
  abstract  = {Did you ever wonder why cheap wine tastes better in fancy glasses? Why sales of Macintosh computers soared when Apple introduced the colorful iMac? New research on emotion and cognition has shown that attractive things really do work better, as Donald Norman amply demonstrates in this fascinating book, which has garnered acclaim everywhere from "Scientific American" to "The New Yorker." "Emotional Design" articulates the profound influence of the feelings that objects evoke, from our willingness to spend thousands of dollars on Gucci bags and Rolex watches, to the impact of emotion on the everyday objects of tomorrow. Norman draws on a wealth of examples and the latest scientific insights to present a bold exploration of the objects in our everyday world. "Emotional Design" will appeal not only to designers and manufacturers but also to managers, psychologists, and general readers who love to think about their stuff.},
  address   = {New York},
  comment   = {Did you ever wonder why cheap wine tastes better in fancy glasses? Why sales of Macintosh computers soared when Apple introduced the colorful iMac? New research on emotion and cognition has shown that attractive things really do work better, as Donald Norman amply demonstrates in this fascinating book, which has garnered acclaim everywhere from "Scientific American" to "The New Yorker." "Emotional Design" articulates the profound influence of the feelings that objects evoke, from our willingness to spend thousands of dollars on Gucci bags and Rolex watches, to the impact of emotion on the everyday objects of tomorrow. Norman draws on a wealth of examples and the latest scientific insights to present a bold exploration of the objects in our everyday world. "Emotional Design" will appeal not only to designers and manufacturers but also to managers, psychologists, and general readers who love to think about their stuff. Includes bibliographical references (pages 243-248) and index.},
  issn      = {1-280-59856-5},
  keywords  = {Emotions and cognition, Design -- Psychological aspects, Industrial design -- Psychological aspects, Electronic books},
  publisher = {Basic Books},
  refid     = {BIBSYS_ILS71521661570002201},
}

@Book{Fogg2002,
  author    = {Fogg, B. J.},
  title     = {Persuasive Technology: Using Computers to Change What We Think and Do},
  year      = {2002},
  series    = {Interactive Technologies},
  publisher = {Elsevier Science},
  comment   = {Can computers change what you think and do? Can they motivate you to stop smoking, persuade you to buy insurance, or convince you to join the Army? <br><br>Yes, they can, says Dr. B.J. Fogg, director of the Persuasive Technology Lab at Stanford University. Fogg has coined the phrase Captology(an acronym for computers as persuasive technologies) to capture the domain of research, design, and applications of persuasive computers.In this thought-provoking book, based on nine years of research in captology, Dr. Fogg reveals how Web sites, software applications, and mobile devices can be used to change people's attitudes and behavior. Technology designers, marketers, researchers, consumers-anyone who wants to leverage or simply understand the persuasive power of interactive technology-will appreciate the compelling insights and illuminating examples found inside. <br><br>Persuasive technology can be controversial-and it should be. Who will wield this power of digital influence? And to what end? Now is the time to survey the issues and explore the principles of persuasive technology, and B.J. Fogg has written this book to be your guide.<br><br>* Filled with key term definitions in persuasive computing<br>*Provides frameworks for understanding this domain<br>*Describes real examples of persuasive technologies},
  issn      = {1558606432},
  keywords  = {Computer -- Cyberkultur -- Sonstiges -- Informatik;},
  refid     = {TN_els_book_whole9781558606432},
}

@Other{Disalvo2002,
  author   = {Disalvo, Carl and Gemperle, Francine and Forlizzi, Jodi and Kiesler, Sara},
  title    = {All robots are not created equal: the design and perception of humanoid robot heads},
  year     = {2002},
  abstract = {<p>This paper presents design research conducted as part of a larger project on human-robot interaction. The primary goal of this study was to come to an initial understanding of what features and dimensions of a humanoid robot's face most dramatically contribute to people's perception of its humanness. To answer this question we analyzed 48 robots and conducted surveys to measure people's perception of each robot's humanness. Through our research we found that the presence of certain features, the dimensions of the head, and the total number of facial features heavily influence the perception of humanness in robot heads. This paper presents our findings and initial guidelines for the design of humanoid robot heads.</p>},
  comment  = {This paper presents design research conducted as part of a larger project on human-robot interaction. The primary goal of this study was to come to an initial understanding of what features and dimensions of a humanoid robot's face most dramatically contribute to people's perception of its humanness. To answer this question we analyzed 48 robots and conducted surveys to measure people's perception of each robot's humanness. Through our research we found that the presence of certain features, the dimensions of the head, and the total number of facial features heavily influence the perception of humanness in robot heads. This paper presents our findings and initial guidelines for the design of humanoid robot heads.},
  issn     = {1581135157},
  keywords = {Design Research, Human-Robot Interaction, Interaction Design, Social Robots, Computer Science},
  pages    = {321--326},
  refid    = {TN_acm778756},
  series   = {DIS '02},
}

@Book{Reeves1996,
  author    = {Reeves, Byron and Nass, Clifford},
  title     = {The media equation : how people treat computers, television and new media like real people and places},
  year      = {1996},
  publisher = {Cambridge University Press},
  address   = {New York},
  comment   = {Bibliografi: s. 259-298},
  issn      = {157586052X},
  keywords  = {massemedier, påvirkning, publikum, fb, massemedia, psykologi, informasjonsteknologi, psykologiske-aspekter, Multimedia, Massemedia -- Psykologi, Sosiologi, Massemedia},
  refid     = {BIBSYS_ILS71492740880002201},
}

@Other{Eyssel2010,
  author   = {Eyssel, Friederike and Hegel, Frank and Horstmann, Gernot and Wagner, Claudia},
  title    = {Anthropomorphic inferences from emotional nonverbal cues: A case study},
  year     = {2010},
  abstract = {We examined the effects of a robots' nonverbal response on evaluations of anthropomorphism and other dimensions (e.g., liking, closeness, pleasantness of human-robot interaction) in a case study. Our work both conceptually replicates and extends previous research: On the one hand, we replicated previous findings and generalized them to a different robot type, the iCat. On the other hand, our work extends existing research in that it includes a wider range of dependent variables, with a particular focus on perceptions of anthropomorphism. Taken together, most of our results support the experimental hypotheses for the dependent measures: That is, a robot that provided emotional feedback during the interaction was perceived to be superior to a robot that responded neutrally. Thus, our findings highlight the importance of the interplay of form and function in the attribution of humanness to robots.},
  comment  = {We examined the effects of a robots' nonverbal response on evaluations of anthropomorphism and other dimensions (e.g., liking, closeness, pleasantness of human-robot interaction) in a case study. Our work both conceptually replicates and extends previous research: On the one hand, we replicated previous findings and generalized them to a different robot type, the iCat. On the other hand, our work extends existing research in that it includes a wider range of dependent variables, with a particular focus on perceptions of anthropomorphism. Taken together, most of our results support the experimental hypotheses for the dependent measures: That is, a robot that provided emotional feedback during the interaction was perceived to be superior to a robot that responded neutrally. Thus, our findings highlight the importance of the interplay of form and function in the attribution of humanness to robots.},
  issn     = {978-1-4244-7991-7},
  journal  = {RO-MAN, 2010 IEEE},
  pages    = {646--651},
  refid    = {TN_ieee10.1109/ROMAN.2010.5598687},
}

@Other{Riek2009,
  author   = {Riek, L. D. and Rabinowitch, T. and Chakrabarti, B. and Robinson, P.},
  title    = {How anthropomorphism affects empathy toward robots},
  year     = {2009},
  abstract = {A long-standing question within the robotics community is about the degree of human-likeness robots ought to have when interacting with humans. We explore an unexamined aspect of this problem: how people empathize with robots along the anthropomorphic spectrum. We conducted an experiment that measured how people empathized with robots shown to be experiencing mistreatment by humans. Our results indicate that people empathize more strongly with more human-looking robots and less with mechanical-looking robots.},
  comment  = {A long-standing question within the robotics community is about the degree of human-likeness robots ought to have when interacting with humans. We explore an unexamined aspect of this problem: how people empathize with robots along the anthropomorphic spectrum. We conducted an experiment that measured how people empathized with robots shown to be experiencing mistreatment by humans. Our results indicate that people empathize more strongly with more human-looking robots and less with mechanical-looking robots.},
  issn     = {978-1-60558-404-1},
  journal  = {Human-Robot Interaction (HRI), 2009 4th ACM/IEEE International Conference on},
  keywords = {Robots, Humans, Abstracts, Seismic Measurements, Human Factors, Experimentation, Robotics and Control Systems, Signal Processing and Analysis, Communication, Networking and Broadcast Technologies, Components, Circuits, Devices and Systems, Computing and Processing},
  pages    = {245--246},
  refid    = {TN_ieee10.1145/1514095.1514158},
}

@Article{Krach2008,
  author   = {Krach, Sören and Hegel, Frank and Wrede, Britta and Sagerer, Gerhard and Binkofski, Ferdinand and Kircher, Tilo and Robertson, Edwin},
  title    = {Can Machines Think? Interaction and Perspective Taking with Robots Investigated via fMRI (ToM on Robots)},
  journal  = {PLoS ONE},
  year     = {2008},
  volume   = {3},
  number   = {7},
  pages    = {e2597},
  abstract = {When our PC goes on strike again we tend to curse it as if it were a human being. Why and under which circumstances do we attribute human-like properties to machines? Although humans increasingly interact directly with machines it remains unclear whether humans implicitly attribute intentions to them and, if so, whether such interactions resemble human-human interactions on a neural level. In social cognitive neuroscience the ability to attribute intentions and desires to others is being referred to as having a Theory of Mind (ToM). With the present study we investigated whether an increase of human-likeness of interaction partners modulates the participants' ToM associated cortical activity.
By means of functional magnetic resonance imaging (subjects n = 20) we investigated cortical activity modulation during highly interactive human-robot game. Increasing degrees of human-likeness for the game partner were introduced by means of a computer partner, a functional robot, an anthropomorphic robot and a human partner. The classical iterated prisoner's dilemma game was applied as experimental task which allowed for an implicit detection of ToM associated cortical activity. During the experiment participants always played against a random sequence unknowingly to them. Irrespective of the surmised interaction partners' responses participants indicated having experienced more fun and competition in the interaction with increasing human-like features of their partners. Parametric modulation of the functional imaging data revealed a highly significant linear increase of cortical activity in the medial frontal cortex as well as in the right temporo-parietal junction in correspondence with the increase of human-likeness of the interaction partner (computer<functional robot<anthropomorphic robot<human).
Both regions correlating with the degree of human-likeness, the medial frontal cortex and the right temporo-parietal junction, have been associated with Theory-of-Mind. The results demonstrate that the tendency to build a model of another's mind linearly increases with its perceived human-likeness. Moreover, the present data provides first evidence of a contribution of higher human cognitive functions such as ToM in direct interactions with artificial robots. Our results shed light on the long-lasting psychological and philosophical debate regarding human-machine interaction and the question of what makes humans being perceived as human.},
  address  = {San Francisco, USA},
  comment  = {When our PC goes on strike again we tend to curse it as if it were a human being. Why and under which circumstances do we attribute human-like properties to machines? Although humans increasingly interact directly with machines it remains unclear whether humans implicitly attribute intentions to them and, if so, whether such interactions resemble human-human interactions on a neural level. In social cognitive neuroscience the ability to attribute intentions and desires to others is being referred to as having a Theory of Mind (ToM). With the present study we investigated whether an increase of human-likeness of interaction partners modulates the participants' ToM associated cortical activity. ; By means of functional magnetic resonance imaging (subjects n = 20) we investigated cortical activity modulation during highly interactive human-robot game. Increasing degrees of human-likeness for the game partner were introduced by means of a computer partner, a functional robot, an anthropomorphic robot and a human partner. The classical iterated prisoner's dilemma game was applied as experimental task which allowed for an implicit detection of ToM associated cortical activity. During the experiment participants always played against a random sequence unknowingly to them. Irrespective of the surmised interaction partners' responses participants indicated having experienced more fun and competition in the interaction with increasing human-like features of their partners. Parametric modulation of the functional imaging data revealed a highly significant linear increase of cortical activity in the medial frontal cortex as well as in the right temporo-parietal junction in correspondence with the increase of human-likeness of the interaction partner (computer&lt;functional robot&lt;anthropomorphic robot&lt;human). ; Both regions correlating with the degree of human-likeness, the medial frontal cortex and the right temporo-parietal junction, have been associated with Theory-of-Mind. The results demonstrate that the tendency to build a model of another's mind linearly increases with its perceived human-likeness. Moreover, the present data provides first evidence of a contribution of higher human cognitive functions such as ToM in direct interactions with artificial robots. Our results shed light on the long-lasting psychological and philosophical debate regarding human-machine interaction and the question of what makes humans being perceived as human.},
  keywords = {Research Article, Neuroscience -- Cognitive Neuroscience, Physiology -- Cognitive Neuroscience, Neuroscience -- Experimental Psychology},
  refid    = {TN_plos10.1371/journal.pone.0002597},
}

@Article{Visser2017,
  author   = {de Visser, Ewart J. and Monfort, Samuel S. and Goodyear, Kimberly and Lu, Li and O’Hara, Martin and Lee, Mary R. and Parasuraman, Raja and Krueger, Frank},
  title    = {A Little Anthropomorphism Goes a Long Way},
  journal  = {Human Factors: The Journal of Human Factors and Ergonomics Society},
  year     = {2017},
  volume   = {59},
  number   = {1},
  pages    = {116--133},
  issn     = {0018-7208},
  abstract = {Objective: We investigated the effects of exogenous oxytocin on trust, compliance, and team decision making with agents varying in anthropomorphism (computer, avatar, human) and reliability (100%, 50%). Background: Authors of recent work have explored psychological similarities in how people trust humanlike automation compared with how they trust other humans. Exogenous administration of oxytocin, a neuropeptide associated with trust among humans, offers a unique opportunity to probe the anthropomorphism continuum of automation to infer when agents are trusted like another human or merely a machine. Method: Eighty-four healthy male participants collaborated with automated agents varying in anthropomorphism that provided recommendations in a pattern recognition task. Results: Under placebo, participants exhibited less trust and compliance with automated aids as the anthropomorphism of those aids increased. Under oxytocin, participants interacted with aids on the extremes of the anthropomorphism continuum similarly to placebos but increased their trust, compliance, and performance with the avatar, an agent on the midpoint of the anthropomorphism continuum. Conclusion: This study provides the first evidence that administration of exogenous oxytocin affected trust, compliance, and team decision making with automated agents. These effects provide support for the premise that oxytocin increases affinity for social stimuli in automated aids. Application: Designing automation to mimic basic human characteristics is sufficient to elicit behavioral trust outcomes that are driven by neurological processes typically observed in human-human interactions. Designers of automated systems should consider the task, the individual, and the level of anthropomorphism to achieve the desired outcome.},
  comment  = {Objective: We investigated the effects of exogenous oxytocin on trust, compliance, and team decision making with agents varying in anthropomorphism (computer, avatar, human) and reliability (100%, 50%). Background: Authors of recent work have explored psychological similarities in how people trust humanlike automation compared with how they trust other humans. Exogenous administration of oxytocin, a neuropeptide associated with trust among humans, offers a unique opportunity to probe the anthropomorphism continuum of automation to infer when agents are trusted like another human or merely a machine. Method: Eighty-four healthy male participants collaborated with automated agents varying in anthropomorphism that provided recommendations in a pattern recognition task. Results: Under placebo, participants exhibited less trust and compliance with automated aids as the anthropomorphism of those aids increased. Under oxytocin, participants interacted with aids on the extremes of the anthropomorphism continuum similarly to placebos but increased their trust, compliance, and performance with the avatar, an agent on the midpoint of the anthropomorphism continuum. Conclusion: This study provides the first evidence that administration of exogenous oxytocin affected trust, compliance, and team decision making with automated agents. These effects provide support for the premise that oxytocin increases affinity for social stimuli in automated aids. Application: Designing automation to mimic basic human characteristics is sufficient to elicit behavioral trust outcomes that are driven by neurological processes typically observed in human-human interactions. Designers of automated systems should consider the task, the individual, and the level of anthropomorphism to achieve the desired outcome.},
  keywords = {Trust In Automation, Oxytocin, Autonomous Agents, Compliance And Reliance, Human-Automation Interaction, Neuroergonomics, Virtual Humans},
  refid    = {TN_sagej10.1177_0018720816687205},
}

@Article{DeAngeli2008,
  author   = {De Angeli, A. and Brahnam, S.},
  title    = {I hate you! Disinhibition with virtual partners},
  journal  = {Interacting With Computers},
  year     = {2008},
  volume   = {20},
  number   = {3},
  pages    = {302--310},
  issn     = {0953-5438},
  comment  = {This paper presents a descriptive lexical analysis of spontaneous conversations between users and the 2005 Loebner prize winning chatterbot, Jabberwacky. The study was motivated in part by the suspicion that evidence in support of the Media Equation, especially in the field of conversational agents, was supported by incomplete data; too often omitted in its purview is the occurrence of unsavoury user responses. Our study shows that conversations with Jabberwacky often bring about the expression of negative verbal disinhibition. We discovered that 10% of the total stems in the corpus reflected abusive language, and approximately 11% of the sample addressed hard-core sex. Users were often rude and violated the conversation maxims of manner, quantity, and relevance. Also particularly pronounced in the conversations was a persistent need of the user to define the speakers' identities (human vs. machine). Users were also curious to understand and test the cognitive capabilities of the chatterbot. Our analysis indicates that the Media Equation may need qualifying, that users treat computers that talk, less as they do people and more as they might treat something not quite an object yet not quite human. [Copyright 2008 Elsevier B.V.]},
  keywords = {Intelligent Agents, Man Machine Interaction, Robots, Computer Applications, Chatterbots, Disinhibition, Verbal Abuse, Sex-Talk, Media Equation, Social Agents, Article;},
  refid    = {TN_wos000256629800003},
}

@Article{Brahnam2012,
  author   = {Brahnam, Sheryl and De Angeli, Antonella},
  title    = {Gender affordances of conversational agents},
  journal  = {Interacting with Computers},
  year     = {2012},
  volume   = {24},
  number   = {3},
  pages    = {139--153},
  issn     = {0953-5438},
  abstract = {Highlights► Gender presentation of conversational agents has an impact on user behaviors. ► Female-presenting agents are the targets of more sex talk. ► Gender stereotypes affect interaction at the relational (style) level. ► Agents presenting with gender increases user disinhibition. Conversational agents are attributed humanlike characteristics
in particular, they are often assumed to have a gender. There is evidence that gender sets up expectations that have an impact on user experiences with agents. The objective of this paper is to explore gender affordances of conversational agents. Our examination takes a holistic approach to the analysis of the application of gender stereotypes to nine chatterbots: six embodied (three male and three female), two disembodied (male and female), and a robot embodiment. Building on social psychology research, we test the persistence of gender stereotypes in the selection of conversation topics and in the elicitation of disinhibition and verbal abuse. Our study is based on quantitative textual analysis of interaction logs. A dictionary of English sexual slang and derogatory terms was developed for this study. Results show that gender stereotypes tend to affect interaction more at the relational (style) level then at the referential (content) level of conversation. People attribute negative stereotypes to female-presenting chatterbots more often than they do to male-presenting chatterbots, and female-presenting chatterbots are more often the objects of implicit and explicit sexual attention and swear words. We conclude by calling for a more informed analysis of user interactions that considers the full range of user interactions.},
  comment  = {Highlights► Gender presentation of conversational agents has an impact on user behaviors. ► Female-presenting agents are the targets of more sex talk. ► Gender stereotypes affect interaction at the relational (style) level. ► Agents presenting with gender increases user disinhibition. Conversational agents are attributed humanlike characteristics; in particular, they are often assumed to have a gender. There is evidence that gender sets up expectations that have an impact on user experiences with agents. The objective of this paper is to explore gender affordances of conversational agents. Our examination takes a holistic approach to the analysis of the application of gender stereotypes to nine chatterbots: six embodied (three male and three female), two disembodied (male and female), and a robot embodiment. Building on social psychology research, we test the persistence of gender stereotypes in the selection of conversation topics and in the elicitation of disinhibition and verbal abuse. Our study is based on quantitative textual analysis of interaction logs. A dictionary of English sexual slang and derogatory terms was developed for this study. Results show that gender stereotypes tend to affect interaction more at the relational (style) level then at the referential (content) level of conversation. People attribute negative stereotypes to female-presenting chatterbots more often than they do to male-presenting chatterbots, and female-presenting chatterbots are more often the objects of implicit and explicit sexual attention and swear words. We conclude by calling for a more informed analysis of user interactions that considers the full range of user interactions.},
  keywords = {Sexuality and Hci, Liwc, Gender, Agent Abuse, Embodied Conversational Agents, Sex Stereotypes},
  refid    = {TN_sciversesciencedirect_elsevierS0953-5438(12)00047-1},
}

@Book{Hogg2005,
  author    = {Hogg, Michael A. and Vaughan, Graham M.},
  title     = {Social psychology},
  year      = {2005},
  edition   = {4th ed.},
  publisher = {Pearson, Prentice Hall},
  address   = {Harlow},
  issn      = {0273686992},
  keywords  = {psykologi, grupper, individer, sosialpsykologi, holdninger, aggresjon, prososial, atferd, tiltrekning, sosial, kognisjon, attribusjon},
  refid     = {BIBSYS_ILS71505053420002201},
}

@Other{Vala2011,
  author  = {Vala, M. and Blanco, G. and Paiva, A.},
  title   = {Providing gender to embodied conversational agents},
  year    = {2011},
  issn    = {9783642239731},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  pages   = {148--154},
  refid   = {TN_scopus2-s2.0-80053206980},
  volume  = {6895},
}

@Other{Kulms2011,
  author   = {Kulms, P. and Krämer, N. C. and Gratch, J. and Kang, S.-H.},
  title    = {It's in their eyes: A study on female and male virtual humans' gaze},
  year     = {2011},
  issn     = {9783642239731},
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Empirical Evaluation, Eye Contact, Female &Amp, Male Virtual Agents, Gender Differences, Gender Stereotypes},
  pages    = {80--92},
  refid    = {TN_scopus2-s2.0-80053215150},
  volume   = {6895},
}

@Article{Xiao2005,
  author  = {Xiao, H. and Reid, D. and Marriott, A. and Gulland, Ek},
  title   = {An adaptive personality model for ECAs},
  journal = {Affective Computing And Intelligent Interaction, Proceedings},
  year    = {2005},
  volume  = {3784},
  pages   = {637--645},
  issn    = {0302-9743},
  refid   = {TN_wos000234342700082},
}

@Other{Cialdini2007,
  author    = {Cialdini, Robert B.},
  title     = {Influence: The Psychology of Persuasion},
  year      = {2007},
  issn      = {0-06-189990-9},
  publisher = {HarperCollins Publishers},
  refid     = {BIBSYS_ILS71528930540002201},
}

@Book{Courage2015,
  author    = {Courage, Catherine and Baxter, Kathy and Caine, Kelly},
  title     = {Understanding Your Users: A Practical Guide to User Research Methods},
  year      = {2015},
  edition   = {Second edition.},
  publisher = {United States: Morgan Kaufmann Publishers Inc},
  abstract  = {This new and completely updated edition is a comprehensive, easy-to-read, "how-to" guide on user research methods. You'll learn about many distinct user research methods and also pre- and post-method considerations such as recruiting, facilitating activities or moderating, negotiating with product developments teams/customers, and getting your results incorporated into the product. For each method, you'll understand how to prepare for and conduct the activity, as well as analyze and present the data - all in a practical and hands-on way. Each method presented provides different information about the users and their requirements (e.g., functional requirements, information architecture). The techniques can be used together to form a complete picture of the users' needs or they can be used separately throughout the product development lifecycle to address specific product questions. These techniques have helped product teams understand the value of user experience research by providing insight into how users behave and what they need to be successful. You will find brand new case studies from leaders in industry and academia that demonstrate each method in action. This book has something to offer whether you are new to user experience or a seasoned UX professional. After reading this book, you'll be able to choose the right user research method for your research question and conduct a user research study. Then, you will be able to apply your findings to your own products. * Completely new and revised edition includes 30+% new content!* Discover the foundation you need to prepare for any user research activity and ensure that the results are incorporated into your products * Includes all new case studies for each method from leaders in industry and academia},
  comment   = {This new and completely updated edition is a comprehensive, easy-to-read, "how-to" guide on user research methods. You'll learn about many distinct user research...},
  issn      = {0128002328},
  keywords  = {User interfaces (Computer systems)},
  refid     = {TN_dawson9780128006092},
}

@Book{Benyon2014,
  author    = {Benyon, David},
  title     = {Designing interactive systems : a comprehensive guide to HCI and interaction design},
  year      = {2014},
  edition   = {3rd ed.},
  publisher = {Pearson},
  address   = {Harlow},
  issn      = {9781447920113},
  keywords  = {brukergrensesnitt, informasjonssystemer, informasjonsteknologi, interaktiv, design, systemanalyse, analyse, web, nett, mobile, apps, menneske, maskin},
  refid     = {BIBSYS_ILS71501339290002201},
}

@Article{McNeal2013,
  author   = {McNeal, Michele L. and Newyear, David},
  title    = {Chapter 1: Introducing chatbots in libraries.(Streamlining Information Services Using Chatbots)(Report)},
  year     = {2013},
  volume   = {49},
  number   = {8},
  pages    = {5},
  issn     = {0024-2586},
  comment  = {Chapter 1 of Library Technology Reports (vol. 49, no. 8), “Streamlining Information Services Using Chatbots,” presents a brief history of chatbots, computer programs that use natural language to interact with users. They have existed for nearly fifty years and have been used in libraries since the mid-2000s; chatbots from ELIZA (1966) to Pixel (2010) are introduced .},
  keywords = {Electronic Messaging - Technology Application, Public Services (Libraries) - Technology Application, Intelligent Agents - Usage, Natural Language Processing - Methods},
  refid    = {TN_gale_ofa407107332},
}

@Other{Kothari,
  author    = {Kothari, Amit and Zyane, Rania and Hoover, Joshua},
  title     = {Chatbots for eCommerce: Learn How to Build a Virtual Shopping Assistant},
  journal   = {Chatbots for eCommerce},
  publisher = {Bleeding Edge Press},
  refid     = {BIBSYS_ILS71550591310002201},
}

@Article{Hutson2017,
  author  = {Hutson, Matthew},
  title   = {When will Alexa, Google Assistant, and other ‘chatbots’ finally talk to us like real people?},
  journal = {Science},
  year    = {2017},
  issn    = {0036-8075},
  refid   = {TN_crossref10.1126/science.aan6995},
}

@InCollection{McTear2016b,
  author    = {McTear, Michael and Callejas, Zoraida and Griol, David},
  title     = {Affective Conversational Interfaces},
  booktitle = {The Conversational Interface: Talking to Smart Devices},
  year      = {2016},
  publisher = {Springer International Publishing},
  pages     = {329--357},
  doi       = {10.1007/978-3-319-32967-3_15},
  url       = {https://doi.org/10.1007/978-3-319-32967-3_15},
  abstract  = {In order to build artificial conversational interfaces that display behaviors that are credible and expressive, we should endow them with the capability to recognize, adapt to, and render emotion. In this chapter, we explain how the recognition of emotional aspects is managed within conversational interfaces, including modeling and representation, emotion recognition from physiological signals, acoustics, text, facial expressions, and gesturesGestures and how emotion synthesis is managed through expressive speech and multimodal embodied agents. We also cover the main open tools and databases available for developers wishing to incorporate emotion into their conversational interfaces.},
  address   = {Cham},
}

@InCollection{Fink2012,
  author    = {Fink, Julia},
  title     = {Anthropomorphism and Human Likeness in the Design of Robots and Human-Robot Interaction},
  booktitle = {Social Robotics: 4th International Conference, ICSR 2012, Chengdu, China, October 29-31, 2012. Proceedings},
  year      = {2012},
  editor    = {Ge, Shuzhi Sam and Khatib, Oussama and Cabibihan, John-John and Simmons, Reid and Williams, Mary-Anne},
  publisher = {Springer Berlin Heidelberg},
  pages     = {199--208},
  doi       = {10.1007/978-3-642-34103-8_20},
  url       = {https://doi.org/10.1007/978-3-642-34103-8_20},
  abstract  = {In this literature review we explain anthropomorphism and its role in the design of socially interactive robots and human-robot interaction. We illustrate the social phenomenon of anthropomorphism which describes people’s tendency to attribute lifelike qualities to objects and other non lifelike artifacts. We present theoretical backgrounds from social sciences, and integrate related work from robotics research, including results from experiments with social robots. We present different approaches for anthropomorphic and humanlike form in a robot’s design related to its physical shape, its behavior, and its interaction with humans. This review provides a comprehensive understanding of anthropomorphism in robotics, collects and reports relevant references, and gives an outlook on anthropomorphic human-robot interaction.},
  address   = {Berlin, Heidelberg},
}

@Article{Walters2008,
  author   = {Walters, Michael L. and Syrdal, Dag S. and Dautenhahn, Kerstin and te Boekhorst, René and Koay, Kheng Lee},
  title    = {Avoiding the uncanny valley: robot appearance, personality and consistency of behavior in an attention-seeking home scenario for a robot companion},
  journal  = {Autonomous Robots},
  year     = {2008},
  date     = {February 01},
  volume   = {24},
  number   = {2},
  pages    = {159--178},
  doi      = {10.1007/s10514-007-9058-3},
  url      = {https://doi.org/10.1007/s10514-007-9058-3},
  abstract = {This article presents the results of video-based Human Robot Interaction (HRI) trials which investigated people’s perceptions of different robot appearances and associated attention-seeking features and behaviors displayed by robots with different appearance and behaviors. The HRI trials studied the participants’ preferences for various features of robot appearance and behavior, as well as their personality attributions towards the robots compared to their own personalities. Overall, participants tended to prefer robots with more human-like appearance and attributes. However, systematic individual differences in the dynamic appearance ratings are not consistent with a universal effect. Introverts and participants with lower emotional stability tended to prefer the mechanical looking appearance to a greater degree than other participants. It is also shown that it is possible to rate individual elements of a particular robot’s behavior and then assess the contribution, or otherwise, of that element to the overall perception of the robot by people. Relating participants’ dynamic appearance ratings of individual robots to independent static appearance ratings provided evidence that could be taken to support a portion of the left hand side of Mori’s theoretically proposed ‘uncanny valley’ diagram. Suggestions for future work are outlined.},
}

@Article{Gould1985,
  author    = {Gould, John D. and Lewis, Clayton},
  title     = {Designing for usability: key principles and what designers think},
  journal   = {Commun. ACM},
  year      = {1985},
  volume    = {28},
  number    = {3},
  pages     = {300--311},
  doi       = {10.1145/3166.3170},
  publisher = {ACM},
}

@Article{Weizenbaum1966,
  author    = {Weizenbaum, Joseph},
  title     = {ELIZA\&mdash;a computer program for the study of natural language communication between man and machine},
  journal   = {Commun. ACM},
  year      = {1966},
  volume    = {9},
  number    = {1},
  pages     = {36--45},
  doi       = {10.1145/365153.365168},
  publisher = {ACM},
}

@InProceedings{Terada2015,
  author    = {Terada, Kazunori and Jing, Liang and Yamada, Seiji},
  title     = {Effects of Agent Appearance on Customer Buying Motivations on Online Shopping Sites},
  booktitle = {Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems},
  year      = {2015},
  publisher = {ACM},
  pages     = {929--934},
  doi       = {10.1145/2702613.2732798},
  address   = {Seoul, Republic of Korea},
}
{Graf2015,
  author        = {Graf, Bettina and Kr\&} # 252, Maike and ger and M& #{252, Felix and ller and Ruhland, Alexander and Zech, Andrea},
  title         = {Nombot: simplify food tracking},
  booktitle     = {Proceedings of the 14th International Conference on Mobile and Ubiquitous Multimedia},
  year          = {2015},
  publisher     = {ACM},
  pages         = {360--363},
  doi           = {10.1145/2836041.2841208},
  __markedentry = {[tuvalundesmestad:6]},
  address       = {Linz, Austria},
}

@Article{Mone2016,
  author    = {Mone, Gregory},
  title     = {The edge of the uncanny},
  journal   = {Commun. ACM},
  year      = {2016},
  volume    = {59},
  number    = {9},
  pages     = {17--19},
  doi       = {10.1145/2967977},
  publisher = {ACM},
}

@Article{Furnham1996,
  author  = {Furnham, Adrian},
  title   = {The big five versus the big four: the relationship between the Myers-Briggs Type Indicator (MBTI) and NEO-PI five factor model of personality},
  journal = {Personality and Individual Differences},
  year    = {1996},
  volume  = {21},
  number  = {2},
  month   = aug,
  pages   = {303--307},
  issn    = {0191-8869},
  url     = {http://www.sciencedirect.com/science/article/pii/0191886996000335},
}

@Article{Casidy2009,
  author    = {Casidy, Riza and Tsarenko, Yelena and Anderson, Alastair},
  title     = {The Big Five and Brand Personality: Investigating the Impact of Consumer Personality on Preferences Towards Particular Brand Personality},
  year      = {2009},
  volume    = {16},
  month     = {01},
  pages     = {234-247},
  booktitle = {Journal of Brand Management},
}

@InProceedings{walker1997paradise,
  author       = {Walker, Marilyn A and Litman, Diane J and Kamm, Candace A and Abella, Alicia},
  title        = {PARADISE: A framework for evaluating spoken dialogue agents},
  booktitle    = {Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics},
  year         = {1997},
  organization = {Association for Computational Linguistics},
  pages        = {271--280},
}

@InProceedings{Author2009,
  author        = {IEEE Staff Corporate Author},
  title         = {Towards a method for evaluating naturalness in conversational dialog systems},
  booktitle     = {2009 IEEE International Conference on Systems, Man and Cybernetics},
  year          = {2009},
  series        = {2009 IEEE International Conference on Systems, Man and Cybernetics - SMC},
  publisher     = {I E E E},
  isbn          = {1-4244-2793-2},
  pages         = {1236--1241},
  __markedentry = {[tuvalundesmestad:]},
  address       = {[Place of publication not identified]},
}

@Article{Callejas2014,
  author        = {Zoraida Callejas and David Griol and Ramón López-Cózar},
  title         = {A framework for the assessment of synthetic personalities according to user perception},
  journal       = {International Journal of Human-Computer Studies},
  year          = {2014},
  volume        = {72},
  number        = {7},
  pages         = {567 - 583},
  issn          = {1071-5819},
  doi           = {https://doi.org/10.1016/j.ijhcs.2014.02.002},
  url           = {http://www.sciencedirect.com/science/article/pii/S1071581914000263},
  __markedentry = {[tuvalundesmestad:6]},
  abstract      = {Endowing artificial conversational agents with personality is a very promising way to obtain more believable user interactions with robots and computers. However, although many authors have studied how to create an agent׳s personality and how it affects performance and user satisfaction, less attention has been paid to assess whether the designed agent׳s personality corresponds to the users׳ perception, whether it is easily recognizable, and what is the effect that the user׳s own personality has in the discrimination of the agents׳ personality. In this paper we present an assessment framework to address these issues in an integrated way, which in our opinion offers enough flexibility to consider the diversity of application domains and evaluation approaches that can be found in the literature. The framework is based on numerical measures, which facilitate the interpretation of results and makes it possible to compare and rank different agents with respect to the user׳s perception of the rendered personality. In addition, we have developed a tool that implements the framework, which may be very useful for researchers in order to easily evaluate different agent personalities.},
  keywords      = {Personality, Evaluation, Conversational agents, Human–computer interaction, Human–robot interaction},
}

@Comment{jabref-meta: databaseType:biblatex;}
